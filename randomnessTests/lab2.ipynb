{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtPyp-kCInPE"
      },
      "source": [
        "# Laboratorio 2 - Simulación\n",
        "## Integrantes:\n",
        "### Jose David Barona Hernandez\n",
        "### Jennyfer Belalcazar Manrique\n",
        "### Diego Ledesma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R43GG8j6OIRs"
      },
      "outputs": [],
      "source": [
        "#Datos globales\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "from math import sqrt, ceil\n",
        "from scipy.stats import chi2_contingency \n",
        "import random\n",
        "import math\n",
        "\n",
        "#Funcion global para normalizar\n",
        "def normalize(lis,m):\n",
        " lis2 =[]\n",
        " for i in range(len(lis)):\n",
        "  lis2.append(round(lis[i]/ m, 2))\n",
        " return lis2\n",
        "\n",
        " #Normalizar para usar poker\n",
        "def normalize2(lis,m):\n",
        " lis2 =[]\n",
        " for i in range(len(lis)):\n",
        "  lis2.append(round(lis[i]/ m, 3))\n",
        " return lis2\n",
        "\n",
        "#Lista de datos para probar la funciones del punto 2, se espera que pase la prueba\n",
        "N = 1000\n",
        "data = np.random.uniform(0,1,N)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xh_CYSGIyFz"
      },
      "source": [
        "# 1. Implementar los algoritmos de generación de secuencias pseudoaletorias (Von Neuman, congruencia lineal y fibonacci), ejecutarlos y obtener sus salidas en alguna(s) variable(s). Generar secuencias de 1000 datos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X85K0q_0JbS9"
      },
      "source": [
        "# Von neuman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHbt_l7OJeWi",
        "outputId": "39726960-8d42-490b-cca0-7173f6fbcf0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3168, 362, 1310, 7161, 2799, 8344, 6223, 7257, 6640, 896, 8028, 4487, 1331, 7715, 5212, 1649, 7192, 7248, 5335, 4622, 3628, 1623, 6341, 2082, 3347, 2024, 965, 9312, 7133, 8796, 3696, 6604, 6128, 5523, 5035, 3512, 3341, 1622, 6308, 7908, 5364, 7724, 6601, 5732, 8558, 2393, 7264, 7656, 6143, 7364, 2284, 2166, 6915, 8172, 7815, 742, 5505, 3050, 3025, 1506, 2680, 1824, 3269, 6863, 1007, 140, 196, 384, 1474, 1726, 9790, 8441, 2504, 2700, 2900, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100]\n",
            "[0.32, 0.04, 0.13, 0.73, 0.29, 0.85, 0.64, 0.74, 0.68, 0.09, 0.82, 0.46, 0.14, 0.79, 0.53, 0.17, 0.73, 0.74, 0.54, 0.47, 0.37, 0.17, 0.65, 0.21, 0.34, 0.21, 0.1, 0.95, 0.73, 0.9, 0.38, 0.67, 0.63, 0.56, 0.51, 0.36, 0.34, 0.17, 0.64, 0.81, 0.55, 0.79, 0.67, 0.59, 0.87, 0.24, 0.74, 0.78, 0.63, 0.75, 0.23, 0.22, 0.71, 0.83, 0.8, 0.08, 0.56, 0.31, 0.31, 0.15, 0.27, 0.19, 0.33, 0.7, 0.1, 0.01, 0.02, 0.04, 0.15, 0.18, 1.0, 0.86, 0.26, 0.28, 0.3, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42, 0.83, 0.62, 0.21, 0.42]\n"
          ]
        }
      ],
      "source": [
        "#Funcion que recibe un numero de tipo int\n",
        "def vonNeuman(n):\n",
        "    dig_count = 4\n",
        "    sqr = n**2\n",
        "    val = sqr // (10**(dig_count / 2)) \n",
        "    val = int(val % (10**dig_count) ) \n",
        "    return val\n",
        "\n",
        "#Funcion que recibe un numero de tipo int y el tamaño de la lista a generar\n",
        "def vonNeumanList(n, length):\n",
        "    lis = []\n",
        "    a = n\n",
        "    for _ in range(length):\n",
        "        lis.append(a)\n",
        "        a = vonNeuman(a)\n",
        "    return lis\n",
        "\n",
        "n = 3168 #Numero inicial\n",
        "length = 1000 #Tamaño del array\n",
        "\n",
        "#Lista sin normalizar \n",
        "lis = vonNeumanList(n, length)\n",
        "print(lis)\n",
        "m=max(lis)\n",
        "\n",
        "#Lista normalizada\n",
        "lis2 = normalize(lis,m)\n",
        "print(lis2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxK56imVJLxg"
      },
      "source": [
        "# Congruencia lineal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG6epX1EJQAu",
        "outputId": "d09d6203-56a4-4c41-f6f1-b41021b056ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[999, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127, 175, 295, 278, 77, 50, 141, 210, 224, 259, 188, 169, 280, 82, 221, 93, 90, 241, 143, 215, 78, 211, 68, 186, 164, 109, 130, 24, 76, 206, 214, 234, 284, 92, 246, 314, 167, 275, 228, 269, 213, 73, 40, 116, 306, 147, 225, 103, 115, 145, 220, 249, 163, 265, 203, 48, 136, 39, 272, 62, 171, 285, 253, 173, 290, 107, 125, 170, 124, 9, 197, 33, 257, 183, 315, 11, 202, 204, 209, 63, 15, 212, 229, 113, 140, 49, 297, 283, 248, 2, 21, 227, 108, 286, 97, 100, 266, 47, 292, 112, 296, 122, 4, 26, 81, 60, 166, 114, 301, 293, 273, 223, 98, 261, 193, 23, 232, 279, 238, 294, 117, 150, 74, 201, 43, 282, 87, 75, 45, 287, 258, 27, 242, 304, 142, 54, 151, 235, 128, 19, 222, 254, 17, 217, 83, 65, 20, 66, 181, 310, 157, 250, 7, 192, 179, 305, 303, 298, 127]\n",
            "[3.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4, 0.55, 0.93, 0.88, 0.24, 0.16, 0.44, 0.66, 0.71, 0.82, 0.59, 0.53, 0.88, 0.26, 0.7, 0.29, 0.28, 0.76, 0.45, 0.68, 0.25, 0.67, 0.21, 0.59, 0.52, 0.34, 0.41, 0.08, 0.24, 0.65, 0.68, 0.74, 0.9, 0.29, 0.78, 0.99, 0.53, 0.87, 0.72, 0.85, 0.67, 0.23, 0.13, 0.37, 0.97, 0.46, 0.71, 0.32, 0.36, 0.46, 0.69, 0.79, 0.51, 0.84, 0.64, 0.15, 0.43, 0.12, 0.86, 0.2, 0.54, 0.9, 0.8, 0.55, 0.91, 0.34, 0.39, 0.54, 0.39, 0.03, 0.62, 0.1, 0.81, 0.58, 0.99, 0.03, 0.64, 0.64, 0.66, 0.2, 0.05, 0.67, 0.72, 0.36, 0.44, 0.15, 0.94, 0.89, 0.78, 0.01, 0.07, 0.72, 0.34, 0.9, 0.31, 0.32, 0.84, 0.15, 0.92, 0.35, 0.93, 0.38, 0.01, 0.08, 0.26, 0.19, 0.52, 0.36, 0.95, 0.92, 0.86, 0.7, 0.31, 0.82, 0.61, 0.07, 0.73, 0.88, 0.75, 0.93, 0.37, 0.47, 0.23, 0.63, 0.14, 0.89, 0.27, 0.24, 0.14, 0.91, 0.81, 0.09, 0.76, 0.96, 0.45, 0.17, 0.48, 0.74, 0.4, 0.06, 0.7, 0.8, 0.05, 0.68, 0.26, 0.21, 0.06, 0.21, 0.57, 0.98, 0.5, 0.79, 0.02, 0.61, 0.56, 0.96, 0.96, 0.94, 0.4]\n"
          ]
        }
      ],
      "source": [
        "#Funcionq ue recibe semilla int, a int, c int, m int\n",
        "def congruencia(rand, a, c, m):\n",
        "    rand = (a*rand + c) % (m)  \n",
        "    return rand\n",
        "\n",
        "def congruenciaList(n, length, a , c, m):\n",
        "    lis = []\n",
        "    for _ in range(length):\n",
        "        lis.append(n)\n",
        "        n = congruencia(n, a, c, m)\n",
        "    return lis\n",
        "\n",
        "n = 999 #Semilla\n",
        "length = 2000 #Tamaño del array\n",
        "a = 16645 \n",
        "c = 13647 \n",
        "m = 317 \n",
        "\n",
        "#Lista sin normalizar \n",
        "lis = congruenciaList(n, length, a, c, m)\n",
        "print(lis)\n",
        "\n",
        "#Lista sin normalizar \n",
        "lis2 = normalize(lis,m)\n",
        "print(lis2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3.69 0.46 0.69 0.98 0.99 0.01 0.6  0.67 0.9  0.21 0.81 0.9  0.73 0.11\n",
            " 0.94 0.34 0.76 0.24 0.89 0.68 0.93 0.8  0.88 0.14 0.04 0.7  0.03 0.17\n",
            " 0.14 0.07 0.3  0.1  0.4  0.46 0.66 0.39 0.92 0.78 0.29 0.07 0.81 0.39\n",
            " 0.43 0.07 0.32 0.69 0.46 0.69 0.98 0.99 0.01 0.6  0.67 0.9  0.21 0.81\n",
            " 0.9  0.73 0.11 0.94 0.34 0.76 0.24 0.89 0.68 0.93 0.8  0.88 0.14 0.04\n",
            " 0.7  0.03 0.17 0.14 0.07 0.3  0.1  0.4  0.46 0.66 0.39 0.92 0.78 0.29\n",
            " 0.07 0.81 0.39 0.43 0.07 0.32 0.69 0.46 0.69 0.98 0.99 0.01 0.6  0.67\n",
            " 0.9  0.21]\n"
          ]
        }
      ],
      "source": [
        "a = 139\n",
        "c = 17\n",
        "m = 271\n",
        "x0 = 9\n",
        "length = 100\n",
        "list8E1 = np.array(congruenciaList(n, length, a , c, m))\n",
        "normalized8E1 = np.array(normalize(list8E1,m)) #np.max(list8E1)))\n",
        "print(normalized8E1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX-m6qD-JsQY"
      },
      "source": [
        "# fibonacci"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtIeunD4Jva6",
        "outputId": "b29d1ac8-4275-4294-f503-cff93db7cdb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 2 38 32 16 54 45  1 34 21 46 37 23 11 27 49 19 46 18 46 19 49 27 11 23\n",
            " 37 46 21 34  1 45 54 16 32 38  2 44 50  5  3 21 39 17 39 25 15 56 21 56\n",
            " 15 25 39 17 11 21 19 31 47 26 13 26  5 29 39 56 51 26 31 54 49 13  3 25\n",
            " 26 31 46 28 25 16 29  1 57 44 31 31 54 29 22  6 45 38 10 26  6 41 43 22\n",
            " 33 26 25 51 41 36 17 34 43 55 46 17 49  1  4 13 21 34 41 31 14 24 47 23\n",
            " 36 34  3 12 57 52 31 31 21  3 55 58 41 27 42 17 36 10  1 18 24 38 45 57\n",
            " 53 20 49 54 44  5 29 52 46 50 47 43 29 43 29 52 15 22 33 31  1 32 26 16\n",
            " 21 24 34 50 18 11 42 40  1 11 45 35 29 26 38 51 29 53 10 16 47 27 57 40\n",
            " 17 48 21 52 32 17 58 42 58 24 47 37 26 49 40  9 52  5 33  8  6 47 12 19\n",
            " 30  1 30 52 58 48 37 47 48 35 31 37 12 48 32 37 54 40 50 42 51 29 51 24\n",
            " 29 13 16 43 14 19 53 43 40 37 25  0 43 13  8 24 45 46 15 10 55 47 29 16\n",
            " 17 34 58 10  2 46 36 22  5 13 13 44  9 34  8  6 32 23 31 45 19 30 50 22\n",
            "  4 25 11 32  2 35 31  7 28 26 57 54 39 44 55 36  0 11 26 50 27  6 19 56\n",
            " 38 24 45 35 18 58 23 29 41  2 19 41 10 43  5  8 54 36 12 25  1 38 26  7\n",
            " 28 29 54 23 33 38  6 41 54  2 44 19 13 29 53 24 40  4 49 13 40  6 23 22\n",
            " 11 33  6 12 14 14 10 31 17 38 28  0 32 42 53 10 38 15 15 31 42 51  3  3\n",
            " 34 35 19 54  2  5 40 38  6 47  3 29 51 30 13 12  9 22 36 57  1 30 13 48\n",
            "  0 45 18 27  2 41 23 42  4 49 37 11 58 44 57 41 28  2 43 49 44  6 30 37\n",
            "  5 26  4 54 26 10 24 35 22 18 46 16 22 46  5 38  8  2 51 15 44 54 58 23\n",
            " 56 31 58 52  1 39 20 51 26 49  6 12 29 50 31 31 27 46 41 57 37 28 38 10\n",
            " 17 43 58 42 17 50  1 39  0 41 35 28 31 37 39 23 55 10 37  3  3 19  5 22\n",
            " 44  2  5 35 43 16 23 31  7 12 49 44 55 54  3 15 45 42 29 56 56 25 35 25\n",
            " 31  2 22  6 54 55 53  1 52 58  9 13 52 52  5  0 21  9  6 53 35 23 56 41\n",
            " 33 12 49 30 43 30 37 17  2  3 26 58 20 15 46 15 24 22 26 18  5 23  0 16\n",
            " 19 47 58  0 48 39 15 55  2 34 23 40 12  0  0  2  9 39 35 12  2  1 51 26\n",
            " 52  6 45 10 21  6  2  2 32 41 34 27 41 12 25  2  5 46 48 16  2  7  0 32\n",
            " 53  7 39 17 20 22  2  2  6 47 26 30 17  6  9  2  8 44 44 46 54  9 16  6\n",
            "  6 17 41  1 45 50 15 50  6 42 20 49 30 51  6  2 17 25  3  8 19 17 40 32\n",
            " 43 38 29 50 56 40 13 56  6 20 40 16 16 25 37 52 17 24 58 11 52 44 55 20\n",
            " 29 38 16 35 19 10 38 47 47 55 12 58 31 46 42 19 52 10 30 53 41  4 48 24\n",
            " 38 48 40 10 45 26 31 22 46  1  6 31 54 10  1 46 10 42 56 52 57 31 26  0\n",
            " 33 40 57 15 30 24 49 44 50 50  9 30 44 38  8 11  2 17 34 40 34 54 36 46\n",
            " 26  1 52 56 47 18 28 10 36 22  8 18 17 52 24 53  2 34 42 16 16 55 21 17\n",
            " 29 32 40 15 11 42 31 17 54  6 49 14 52 15 22 50 17 48 34 17 16 47 50 44\n",
            " 54 58 16 40 18  1 15 58 56 36 41 14 38 22 50 49 42 34 29 52 12 23 44 54\n",
            " 44 17 41  5 21 31 37 40 33  8 41 44  1 17 21 19 18 18 44  9 25 26 33 26\n",
            " 21 21 54 31 28 40 22 49 48 50 24 39 57  7 10 38 49 41  5 33 39  0  3 49\n",
            " 15 52 48 42  7  0  3 35 16 58 32 45  4 33  2 42 37 22 32 57  6 21  2  9\n",
            "  6  3 11  3 46 53 56 22  5 45 19 44 54  0  2  8 30 33 40 58 10 29  2 52\n",
            "  5 23 16 20 35 41  2  6 43 50 20 43  4  3 21  6 57 32 12  1  3 19 51 55\n",
            " 16 40 10 28  6 41  2 44 50  1 55 10  1 32 22 45 30 23 37 44 31 35 31  6\n",
            " 30 28 52 40 19  6 39 51 36  1 30 33 46 36 18 49]\n",
            "[0.03 0.64 0.54 0.27 0.92 0.76 0.02 0.58 0.36 0.78 0.63 0.39 0.19 0.46\n",
            " 0.83 0.32 0.78 0.31 0.78 0.32 0.83 0.46 0.19 0.39 0.63 0.78 0.36 0.58\n",
            " 0.02 0.76 0.92 0.27 0.54 0.64 0.03 0.75 0.85 0.08 0.05 0.36 0.66 0.29\n",
            " 0.66 0.42 0.25 0.95 0.36 0.95 0.25 0.42 0.66 0.29 0.19 0.36 0.32 0.53\n",
            " 0.8  0.44 0.22 0.44 0.08 0.49 0.66 0.95 0.86 0.44 0.53 0.92 0.83 0.22\n",
            " 0.05 0.42 0.44 0.53 0.78 0.47 0.42 0.27 0.49 0.02 0.97 0.75 0.53 0.53\n",
            " 0.92 0.49 0.37 0.1  0.76 0.64 0.17 0.44 0.1  0.69 0.73 0.37 0.56 0.44\n",
            " 0.42 0.86 0.69 0.61 0.29 0.58 0.73 0.93 0.78 0.29 0.83 0.02 0.07 0.22\n",
            " 0.36 0.58 0.69 0.53 0.24 0.41 0.8  0.39 0.61 0.58 0.05 0.2  0.97 0.88\n",
            " 0.53 0.53 0.36 0.05 0.93 0.98 0.69 0.46 0.71 0.29 0.61 0.17 0.02 0.31\n",
            " 0.41 0.64 0.76 0.97 0.9  0.34 0.83 0.92 0.75 0.08 0.49 0.88 0.78 0.85\n",
            " 0.8  0.73 0.49 0.73 0.49 0.88 0.25 0.37 0.56 0.53 0.02 0.54 0.44 0.27\n",
            " 0.36 0.41 0.58 0.85 0.31 0.19 0.71 0.68 0.02 0.19 0.76 0.59 0.49 0.44\n",
            " 0.64 0.86 0.49 0.9  0.17 0.27 0.8  0.46 0.97 0.68 0.29 0.81 0.36 0.88\n",
            " 0.54 0.29 0.98 0.71 0.98 0.41 0.8  0.63 0.44 0.83 0.68 0.15 0.88 0.08\n",
            " 0.56 0.14 0.1  0.8  0.2  0.32 0.51 0.02 0.51 0.88 0.98 0.81 0.63 0.8\n",
            " 0.81 0.59 0.53 0.63 0.2  0.81 0.54 0.63 0.92 0.68 0.85 0.71 0.86 0.49\n",
            " 0.86 0.41 0.49 0.22 0.27 0.73 0.24 0.32 0.9  0.73 0.68 0.63 0.42 0.\n",
            " 0.73 0.22 0.14 0.41 0.76 0.78 0.25 0.17 0.93 0.8  0.49 0.27 0.29 0.58\n",
            " 0.98 0.17 0.03 0.78 0.61 0.37 0.08 0.22 0.22 0.75 0.15 0.58 0.14 0.1\n",
            " 0.54 0.39 0.53 0.76 0.32 0.51 0.85 0.37 0.07 0.42 0.19 0.54 0.03 0.59\n",
            " 0.53 0.12 0.47 0.44 0.97 0.92 0.66 0.75 0.93 0.61 0.   0.19 0.44 0.85\n",
            " 0.46 0.1  0.32 0.95 0.64 0.41 0.76 0.59 0.31 0.98 0.39 0.49 0.69 0.03\n",
            " 0.32 0.69 0.17 0.73 0.08 0.14 0.92 0.61 0.2  0.42 0.02 0.64 0.44 0.12\n",
            " 0.47 0.49 0.92 0.39 0.56 0.64 0.1  0.69 0.92 0.03 0.75 0.32 0.22 0.49\n",
            " 0.9  0.41 0.68 0.07 0.83 0.22 0.68 0.1  0.39 0.37 0.19 0.56 0.1  0.2\n",
            " 0.24 0.24 0.17 0.53 0.29 0.64 0.47 0.   0.54 0.71 0.9  0.17 0.64 0.25\n",
            " 0.25 0.53 0.71 0.86 0.05 0.05 0.58 0.59 0.32 0.92 0.03 0.08 0.68 0.64\n",
            " 0.1  0.8  0.05 0.49 0.86 0.51 0.22 0.2  0.15 0.37 0.61 0.97 0.02 0.51\n",
            " 0.22 0.81 0.   0.76 0.31 0.46 0.03 0.69 0.39 0.71 0.07 0.83 0.63 0.19\n",
            " 0.98 0.75 0.97 0.69 0.47 0.03 0.73 0.83 0.75 0.1  0.51 0.63 0.08 0.44\n",
            " 0.07 0.92 0.44 0.17 0.41 0.59 0.37 0.31 0.78 0.27 0.37 0.78 0.08 0.64\n",
            " 0.14 0.03 0.86 0.25 0.75 0.92 0.98 0.39 0.95 0.53 0.98 0.88 0.02 0.66\n",
            " 0.34 0.86 0.44 0.83 0.1  0.2  0.49 0.85 0.53 0.53 0.46 0.78 0.69 0.97\n",
            " 0.63 0.47 0.64 0.17 0.29 0.73 0.98 0.71 0.29 0.85 0.02 0.66 0.   0.69\n",
            " 0.59 0.47 0.53 0.63 0.66 0.39 0.93 0.17 0.63 0.05 0.05 0.32 0.08 0.37\n",
            " 0.75 0.03 0.08 0.59 0.73 0.27 0.39 0.53 0.12 0.2  0.83 0.75 0.93 0.92\n",
            " 0.05 0.25 0.76 0.71 0.49 0.95 0.95 0.42 0.59 0.42 0.53 0.03 0.37 0.1\n",
            " 0.92 0.93 0.9  0.02 0.88 0.98 0.15 0.22 0.88 0.88 0.08 0.   0.36 0.15\n",
            " 0.1  0.9  0.59 0.39 0.95 0.69 0.56 0.2  0.83 0.51 0.73 0.51 0.63 0.29\n",
            " 0.03 0.05 0.44 0.98 0.34 0.25 0.78 0.25 0.41 0.37 0.44 0.31 0.08 0.39\n",
            " 0.   0.27 0.32 0.8  0.98 0.   0.81 0.66 0.25 0.93 0.03 0.58 0.39 0.68\n",
            " 0.2  0.   0.   0.03 0.15 0.66 0.59 0.2  0.03 0.02 0.86 0.44 0.88 0.1\n",
            " 0.76 0.17 0.36 0.1  0.03 0.03 0.54 0.69 0.58 0.46 0.69 0.2  0.42 0.03\n",
            " 0.08 0.78 0.81 0.27 0.03 0.12 0.   0.54 0.9  0.12 0.66 0.29 0.34 0.37\n",
            " 0.03 0.03 0.1  0.8  0.44 0.51 0.29 0.1  0.15 0.03 0.14 0.75 0.75 0.78\n",
            " 0.92 0.15 0.27 0.1  0.1  0.29 0.69 0.02 0.76 0.85 0.25 0.85 0.1  0.71\n",
            " 0.34 0.83 0.51 0.86 0.1  0.03 0.29 0.42 0.05 0.14 0.32 0.29 0.68 0.54\n",
            " 0.73 0.64 0.49 0.85 0.95 0.68 0.22 0.95 0.1  0.34 0.68 0.27 0.27 0.42\n",
            " 0.63 0.88 0.29 0.41 0.98 0.19 0.88 0.75 0.93 0.34 0.49 0.64 0.27 0.59\n",
            " 0.32 0.17 0.64 0.8  0.8  0.93 0.2  0.98 0.53 0.78 0.71 0.32 0.88 0.17\n",
            " 0.51 0.9  0.69 0.07 0.81 0.41 0.64 0.81 0.68 0.17 0.76 0.44 0.53 0.37\n",
            " 0.78 0.02 0.1  0.53 0.92 0.17 0.02 0.78 0.17 0.71 0.95 0.88 0.97 0.53\n",
            " 0.44 0.   0.56 0.68 0.97 0.25 0.51 0.41 0.83 0.75 0.85 0.85 0.15 0.51\n",
            " 0.75 0.64 0.14 0.19 0.03 0.29 0.58 0.68 0.58 0.92 0.61 0.78 0.44 0.02\n",
            " 0.88 0.95 0.8  0.31 0.47 0.17 0.61 0.37 0.14 0.31 0.29 0.88 0.41 0.9\n",
            " 0.03 0.58 0.71 0.27 0.27 0.93 0.36 0.29 0.49 0.54 0.68 0.25 0.19 0.71\n",
            " 0.53 0.29 0.92 0.1  0.83 0.24 0.88 0.25 0.37 0.85 0.29 0.81 0.58 0.29\n",
            " 0.27 0.8  0.85 0.75 0.92 0.98 0.27 0.68 0.31 0.02 0.25 0.98 0.95 0.61\n",
            " 0.69 0.24 0.64 0.37 0.85 0.83 0.71 0.58 0.49 0.88 0.2  0.39 0.75 0.92\n",
            " 0.75 0.29 0.69 0.08 0.36 0.53 0.63 0.68 0.56 0.14 0.69 0.75 0.02 0.29\n",
            " 0.36 0.32 0.31 0.31 0.75 0.15 0.42 0.44 0.56 0.44 0.36 0.36 0.92 0.53\n",
            " 0.47 0.68 0.37 0.83 0.81 0.85 0.41 0.66 0.97 0.12 0.17 0.64 0.83 0.69\n",
            " 0.08 0.56 0.66 0.   0.05 0.83 0.25 0.88 0.81 0.71 0.12 0.   0.05 0.59\n",
            " 0.27 0.98 0.54 0.76 0.07 0.56 0.03 0.71 0.63 0.37 0.54 0.97 0.1  0.36\n",
            " 0.03 0.15 0.1  0.05 0.19 0.05 0.78 0.9  0.95 0.37 0.08 0.76 0.32 0.75\n",
            " 0.92 0.   0.03 0.14 0.51 0.56 0.68 0.98 0.17 0.49 0.03 0.88 0.08 0.39\n",
            " 0.27 0.34 0.59 0.69 0.03 0.1  0.73 0.85 0.34 0.73 0.07 0.05 0.36 0.1\n",
            " 0.97 0.54 0.2  0.02 0.05 0.32 0.86 0.93 0.27 0.68 0.17 0.47 0.1  0.69\n",
            " 0.03 0.75 0.85 0.02 0.93 0.17 0.02 0.54 0.37 0.76 0.51 0.39 0.63 0.75\n",
            " 0.53 0.59 0.53 0.1  0.51 0.47 0.88 0.68 0.32 0.1  0.66 0.86 0.61 0.02\n",
            " 0.51 0.56 0.78 0.61 0.31 0.83]\n",
            "[53 37 31  9 40 49 30 20 50 11  2 13 15 28 43 12 55  8  4 12 16 28 44 13\n",
            " 57 11  9 20 29 49 19  9 28 37  6 43 49 33 23 56 20 51 48 40 29 10 39 49\n",
            " 29 19 48  8 56  5  2  7  9 16  0 52 52 45 38 24  3 27 30 57 28 26 54 21\n",
            " 16 37 53  6 36 42 19  2 21 23 19 19 38 57 36 34 11 45 56 42 14 33 47 21\n",
            "  9 30 39 19 12 31 43 15 58 14 13 27 40 42  0 42 42 25  8 33 25 48 14  3\n",
            " 17 20 37 32 46 19 40 36 17 53 11  5 16 39 22  2 24 26 50 17 51 58 50 24\n",
            " 51 16  8 24 32 56 22 22 44  7 51 58 50 17 47  5 27  9 36 45 56 19 16  3\n",
            " 58  2  1  3  4  7 56 10  7 51 35 27  3 48 18  7 27 50 18  9 27 36  4 19\n",
            " 32 51 58 27 26 53  6  6 12 54  0 54 54 24 55 20 22 31 53  0 30 30  1  3\n",
            " 16 19 46 35 22 57 13 14 27 49 22 12  9 57  7  5 22 48 11 45  3 48 51 19\n",
            " 20 39 44 22  7  4 22  3 25 44 20  5 45 33 19 52 22 36 58 31 57 29  2 35\n",
            " 17 52 34 42 17 54 31 26 57 44 25 10 17  1 18 53 54 37 32 19  5 24 58 53\n",
            " 29 23 29 45 15  3 34 37 46 17 14 31 50  3 53  1 29 46 16  4 28 32 57  6\n",
            "  4 44  2 39 41  8  4 12 54 24 24 48 23 33 56 56  0 33  8 31 25 56 11 38\n",
            " 49 41 41 38 20 14 36 50 57 29 20 24 35 53 29  9 44 53 26 43 18  2 22 40\n",
            "  3 52 53 44 13 58 27 26  6 44 27 34 15 43 58 33 19 52 34 35 23 33 13  4\n",
            " 17  4 14 47 58 50 37 28 42  4 46  1 19 41 35 35 44 20 56  8 32 12 49  5\n",
            " 54 48 48 14 35 34 25 34  9  4 13 31 43 55 45  3  9 12 52  3  2 34 25  3\n",
            "  3 51  8  0 32  3 37 21 38 53 32 49 11 34 46 15  8 57 40 56 14  8 37  3\n",
            " 55 47 57 45 21 54 30 32 18 17 10 33  0 16 42  3  6 58 39  6 45 53 57  8\n",
            " 53 56 11 42 23 11 50 29 18 14 56 20  3  0  2 35 11 49 44  9 28 44  6 21\n",
            "  2 36 31  7 53  3 16 44 38 17 48 24 15 14 38  4 29 55 33 42 49 17 14  7\n",
            " 14 56 31 45 44 18 14 40 39 40 45 18 51 18  2 20 28 16 33  3 52 38 21 30\n",
            " 25 18 57 34 42  7 32 40 24 57 12  7 45 42 55 35 37 39 15 29 20 27 25 46\n",
            " 21  4 38 57 25 37  1 57 55  6 55 48 32 13  6 46 17 46 22 36 32  8 44 33\n",
            " 38 20  4  8 55 18 55  2 22 54 26 37  6 52 35 10 20  0 24 42  6 21 55 56\n",
            "  0 18  1 22 26 38  6 41 56 37 46 46 19 38 29 40 30 38 38  5 30 22 56  2\n",
            " 43 19 32 13 24 25 31  5 50 50 38  3 47 36 43 52 58 43 37 33 35 50  4 37\n",
            " 46 47 28 25 49  7 15 13 33 29 22 16 38  6 13  1 39 30  7  1 38 14 32 46\n",
            " 18 24 20  1 19 26 42 56 53 38 14 44 34 14  5 36 24  5 12 48 26  9 33 57\n",
            " 10 27  8 36  1 13 20 18 37  4 35 19 49  5 23  6 44 28 51 28 37 20 39  3\n",
            " 15 31 42 49  4 24 19 28 42  9 33  4 17  4 29 13  1 25 58 50 26  5 37 39\n",
            " 46 20 13  9 23  7  9 52 19 45 53 50 19  4 25 17 42  2 51 55 58 27 31 28\n",
            " 21  2 54 27 54 36  8 54 30 43 27 50 46 25 32  9  8  8 22  8 36 18 43 17\n",
            " 47 49 29 21 41  6 29 57 26 50 10 14  4 35 45 15 45  9 51 24 48 36 42 37\n",
            " 52 56 34 37  5 50  1 18 24 53 17 14 32 25 54 26 54 40 46  4 58 46 56 30\n",
            " 16 50 44 27 28 36  1 40 41 40 49 38 28 47 23 39  8  9 47 19  5 33 27  2\n",
            " 58  6 34  7 52  1 13 18  6  3 49 34 23  4 20 24 32 15 56 19 34 21 37 14\n",
            " 58 47 43 39 13 51 51 43  4 40 24 44 38 39 54  5 16 57 53 18 46  6 52  5\n",
            "  2 10 43 14 19  2 43 15 29 48 13 50 37 21 27 30 19  1 57 27 53 32 53 35\n",
            " 58 33 29 37 35 16  1 22 35 35 58 51 45 40 38 46 40  1 43 13 51 54 18 44\n",
            " 37  5 24 12 42 23  2  6 17  0  2 41 40 45 27 12]\n",
            "[0.9  0.63 0.53 0.15 0.68 0.83 0.51 0.34 0.85 0.19 0.03 0.22 0.25 0.47\n",
            " 0.73 0.2  0.93 0.14 0.07 0.2  0.27 0.47 0.75 0.22 0.97 0.19 0.15 0.34\n",
            " 0.49 0.83 0.32 0.15 0.47 0.63 0.1  0.73 0.83 0.56 0.39 0.95 0.34 0.86\n",
            " 0.81 0.68 0.49 0.17 0.66 0.83 0.49 0.32 0.81 0.14 0.95 0.08 0.03 0.12\n",
            " 0.15 0.27 0.   0.88 0.88 0.76 0.64 0.41 0.05 0.46 0.51 0.97 0.47 0.44\n",
            " 0.92 0.36 0.27 0.63 0.9  0.1  0.61 0.71 0.32 0.03 0.36 0.39 0.32 0.32\n",
            " 0.64 0.97 0.61 0.58 0.19 0.76 0.95 0.71 0.24 0.56 0.8  0.36 0.15 0.51\n",
            " 0.66 0.32 0.2  0.53 0.73 0.25 0.98 0.24 0.22 0.46 0.68 0.71 0.   0.71\n",
            " 0.71 0.42 0.14 0.56 0.42 0.81 0.24 0.05 0.29 0.34 0.63 0.54 0.78 0.32\n",
            " 0.68 0.61 0.29 0.9  0.19 0.08 0.27 0.66 0.37 0.03 0.41 0.44 0.85 0.29\n",
            " 0.86 0.98 0.85 0.41 0.86 0.27 0.14 0.41 0.54 0.95 0.37 0.37 0.75 0.12\n",
            " 0.86 0.98 0.85 0.29 0.8  0.08 0.46 0.15 0.61 0.76 0.95 0.32 0.27 0.05\n",
            " 0.98 0.03 0.02 0.05 0.07 0.12 0.95 0.17 0.12 0.86 0.59 0.46 0.05 0.81\n",
            " 0.31 0.12 0.46 0.85 0.31 0.15 0.46 0.61 0.07 0.32 0.54 0.86 0.98 0.46\n",
            " 0.44 0.9  0.1  0.1  0.2  0.92 0.   0.92 0.92 0.41 0.93 0.34 0.37 0.53\n",
            " 0.9  0.   0.51 0.51 0.02 0.05 0.27 0.32 0.78 0.59 0.37 0.97 0.22 0.24\n",
            " 0.46 0.83 0.37 0.2  0.15 0.97 0.12 0.08 0.37 0.81 0.19 0.76 0.05 0.81\n",
            " 0.86 0.32 0.34 0.66 0.75 0.37 0.12 0.07 0.37 0.05 0.42 0.75 0.34 0.08\n",
            " 0.76 0.56 0.32 0.88 0.37 0.61 0.98 0.53 0.97 0.49 0.03 0.59 0.29 0.88\n",
            " 0.58 0.71 0.29 0.92 0.53 0.44 0.97 0.75 0.42 0.17 0.29 0.02 0.31 0.9\n",
            " 0.92 0.63 0.54 0.32 0.08 0.41 0.98 0.9  0.49 0.39 0.49 0.76 0.25 0.05\n",
            " 0.58 0.63 0.78 0.29 0.24 0.53 0.85 0.05 0.9  0.02 0.49 0.78 0.27 0.07\n",
            " 0.47 0.54 0.97 0.1  0.07 0.75 0.03 0.66 0.69 0.14 0.07 0.2  0.92 0.41\n",
            " 0.41 0.81 0.39 0.56 0.95 0.95 0.   0.56 0.14 0.53 0.42 0.95 0.19 0.64\n",
            " 0.83 0.69 0.69 0.64 0.34 0.24 0.61 0.85 0.97 0.49 0.34 0.41 0.59 0.9\n",
            " 0.49 0.15 0.75 0.9  0.44 0.73 0.31 0.03 0.37 0.68 0.05 0.88 0.9  0.75\n",
            " 0.22 0.98 0.46 0.44 0.1  0.75 0.46 0.58 0.25 0.73 0.98 0.56 0.32 0.88\n",
            " 0.58 0.59 0.39 0.56 0.22 0.07 0.29 0.07 0.24 0.8  0.98 0.85 0.63 0.47\n",
            " 0.71 0.07 0.78 0.02 0.32 0.69 0.59 0.59 0.75 0.34 0.95 0.14 0.54 0.2\n",
            " 0.83 0.08 0.92 0.81 0.81 0.24 0.59 0.58 0.42 0.58 0.15 0.07 0.22 0.53\n",
            " 0.73 0.93 0.76 0.05 0.15 0.2  0.88 0.05 0.03 0.58 0.42 0.05 0.05 0.86\n",
            " 0.14 0.   0.54 0.05 0.63 0.36 0.64 0.9  0.54 0.83 0.19 0.58 0.78 0.25\n",
            " 0.14 0.97 0.68 0.95 0.24 0.14 0.63 0.05 0.93 0.8  0.97 0.76 0.36 0.92\n",
            " 0.51 0.54 0.31 0.29 0.17 0.56 0.   0.27 0.71 0.05 0.1  0.98 0.66 0.1\n",
            " 0.76 0.9  0.97 0.14 0.9  0.95 0.19 0.71 0.39 0.19 0.85 0.49 0.31 0.24\n",
            " 0.95 0.34 0.05 0.   0.03 0.59 0.19 0.83 0.75 0.15 0.47 0.75 0.1  0.36\n",
            " 0.03 0.61 0.53 0.12 0.9  0.05 0.27 0.75 0.64 0.29 0.81 0.41 0.25 0.24\n",
            " 0.64 0.07 0.49 0.93 0.56 0.71 0.83 0.29 0.24 0.12 0.24 0.95 0.53 0.76\n",
            " 0.75 0.31 0.24 0.68 0.66 0.68 0.76 0.31 0.86 0.31 0.03 0.34 0.47 0.27\n",
            " 0.56 0.05 0.88 0.64 0.36 0.51 0.42 0.31 0.97 0.58 0.71 0.12 0.54 0.68\n",
            " 0.41 0.97 0.2  0.12 0.76 0.71 0.93 0.59 0.63 0.66 0.25 0.49 0.34 0.46\n",
            " 0.42 0.78 0.36 0.07 0.64 0.97 0.42 0.63 0.02 0.97 0.93 0.1  0.93 0.81\n",
            " 0.54 0.22 0.1  0.78 0.29 0.78 0.37 0.61 0.54 0.14 0.75 0.56 0.64 0.34\n",
            " 0.07 0.14 0.93 0.31 0.93 0.03 0.37 0.92 0.44 0.63 0.1  0.88 0.59 0.17\n",
            " 0.34 0.   0.41 0.71 0.1  0.36 0.93 0.95 0.   0.31 0.02 0.37 0.44 0.64\n",
            " 0.1  0.69 0.95 0.63 0.78 0.78 0.32 0.64 0.49 0.68 0.51 0.64 0.64 0.08\n",
            " 0.51 0.37 0.95 0.03 0.73 0.32 0.54 0.22 0.41 0.42 0.53 0.08 0.85 0.85\n",
            " 0.64 0.05 0.8  0.61 0.73 0.88 0.98 0.73 0.63 0.56 0.59 0.85 0.07 0.63\n",
            " 0.78 0.8  0.47 0.42 0.83 0.12 0.25 0.22 0.56 0.49 0.37 0.27 0.64 0.1\n",
            " 0.22 0.02 0.66 0.51 0.12 0.02 0.64 0.24 0.54 0.78 0.31 0.41 0.34 0.02\n",
            " 0.32 0.44 0.71 0.95 0.9  0.64 0.24 0.75 0.58 0.24 0.08 0.61 0.41 0.08\n",
            " 0.2  0.81 0.44 0.15 0.56 0.97 0.17 0.46 0.14 0.61 0.02 0.22 0.34 0.31\n",
            " 0.63 0.07 0.59 0.32 0.83 0.08 0.39 0.1  0.75 0.47 0.86 0.47 0.63 0.34\n",
            " 0.66 0.05 0.25 0.53 0.71 0.83 0.07 0.41 0.32 0.47 0.71 0.15 0.56 0.07\n",
            " 0.29 0.07 0.49 0.22 0.02 0.42 0.98 0.85 0.44 0.08 0.63 0.66 0.78 0.34\n",
            " 0.22 0.15 0.39 0.12 0.15 0.88 0.32 0.76 0.9  0.85 0.32 0.07 0.42 0.29\n",
            " 0.71 0.03 0.86 0.93 0.98 0.46 0.53 0.47 0.36 0.03 0.92 0.46 0.92 0.61\n",
            " 0.14 0.92 0.51 0.73 0.46 0.85 0.78 0.42 0.54 0.15 0.14 0.14 0.37 0.14\n",
            " 0.61 0.31 0.73 0.29 0.8  0.83 0.49 0.36 0.69 0.1  0.49 0.97 0.44 0.85\n",
            " 0.17 0.24 0.07 0.59 0.76 0.25 0.76 0.15 0.86 0.41 0.81 0.61 0.71 0.63\n",
            " 0.88 0.95 0.58 0.63 0.08 0.85 0.02 0.31 0.41 0.9  0.29 0.24 0.54 0.42\n",
            " 0.92 0.44 0.92 0.68 0.78 0.07 0.98 0.78 0.95 0.51 0.27 0.85 0.75 0.46\n",
            " 0.47 0.61 0.02 0.68 0.69 0.68 0.83 0.64 0.47 0.8  0.39 0.66 0.14 0.15\n",
            " 0.8  0.32 0.08 0.56 0.46 0.03 0.98 0.1  0.58 0.12 0.88 0.02 0.22 0.31\n",
            " 0.1  0.05 0.83 0.58 0.39 0.07 0.34 0.41 0.54 0.25 0.95 0.32 0.58 0.36\n",
            " 0.63 0.24 0.98 0.8  0.73 0.66 0.22 0.86 0.86 0.73 0.07 0.68 0.41 0.75\n",
            " 0.64 0.66 0.92 0.08 0.27 0.97 0.9  0.31 0.78 0.1  0.88 0.08 0.03 0.17\n",
            " 0.73 0.24 0.32 0.03 0.73 0.25 0.49 0.81 0.22 0.85 0.63 0.36 0.46 0.51\n",
            " 0.32 0.02 0.97 0.46 0.9  0.54 0.9  0.59 0.98 0.56 0.49 0.63 0.59 0.27\n",
            " 0.02 0.37 0.59 0.59 0.98 0.86 0.76 0.68 0.64 0.78 0.68 0.02 0.73 0.22\n",
            " 0.86 0.92 0.31 0.75 0.63 0.08 0.41 0.2  0.71 0.39 0.03 0.1  0.29 0.\n",
            " 0.03 0.69 0.68 0.76 0.46 0.2 ]\n"
          ]
        }
      ],
      "source": [
        "def fibonacciNumbers(length):\n",
        "  a = 0\n",
        "  b = 1\n",
        "  lst = np.array([a, b])\n",
        "  for i in range (length - 2):\n",
        "    n = a + b\n",
        "    lst = np.append(lst, int(n))\n",
        "    a = b\n",
        "    b = n\n",
        "  return lst\n",
        "\n",
        "\n",
        "def fibonacciElem(index):\n",
        "  if (index == 0):\n",
        "    return 0\n",
        "  elif (index == 1):\n",
        "    return 1\n",
        "  else:\n",
        "    a = 0\n",
        "    b = 1\n",
        "    for i in range (index - 1):\n",
        "      n = a + b\n",
        "      a = b\n",
        "      b = n\n",
        "    return int(n)\n",
        "\n",
        "\n",
        "#Suma\n",
        "def additiveLFG(j, k, m, length):\n",
        "  n = k\n",
        "  lst = np.array([], dtype = np.int64)\n",
        "\n",
        "  #Al inicio el arreglo no es lo suficientemente largo\n",
        "  #para tomar los valores anteriores y se toman los valores de la serie \n",
        "  #de fibonacci.\n",
        "  while ((len(lst) < k) and (len(lst) < length) ):\n",
        "    lst = np.append(lst, int( fibonacciElem(n - j) + fibonacciElem(n - k) ) % m )\n",
        "    n += 1\n",
        "  if (len(lst) == length):\n",
        "    print(\"prem\")\n",
        "    return lst\n",
        "  else:\n",
        "\n",
        "    #Cuando ya es suficientemente largo el arreglo los valores siguientes \n",
        "    #se calculan usando sus propios elementos.\n",
        "    while( len(lst) < length ):\n",
        "      lst = np.append(lst, int( lst[len(lst) - j] + lst[len(lst) - k] ) % m )\n",
        "      n += 1\n",
        "    return lst\n",
        "\n",
        "\n",
        "\n",
        "#Multiplicacion\n",
        "def multiplicativeLFG(j, k, m, c, length):\n",
        "  n = k\n",
        "  lst = np.array([], dtype = np.int64)\n",
        "\n",
        "  #Al inicio el arreglo no es lo suficientemente largo\n",
        "  #para tomar los valores anteriores y se toman los valores de la serie \n",
        "  #de fibonacci.\n",
        "  while ((len(lst) < k) and (len(lst) < length) ):\n",
        "    lst = np.append(lst, int( fibonacciElem(n - j) * fibonacciElem(n - k) + c ) % m )\n",
        "    n += 1\n",
        "  if (len(lst) == length):\n",
        "    print(\"prem\")\n",
        "    return lst\n",
        "  else:\n",
        "\n",
        "    #Cuando ya es suficientemente largo el arreglo los valores siguientes \n",
        "    #se calculan usando sus propios elementos.\n",
        "    while( len(lst) < length ):\n",
        "      lst = np.append(lst, int( lst[len(lst) - j] * lst[len(lst) - k] + c ) % m )\n",
        "      n += 1\n",
        "    return lst\n",
        "\n",
        "m = 59 # 59 es un número primo\n",
        "j = 17\n",
        "k = 41\n",
        "length = 1000\n",
        "#El parámetro c es el valor de la constante aditiva, \n",
        "#la cual impide que la secuencia converja a 0 sin poder salir\n",
        "#de ese valor.\n",
        "c = 2\n",
        "\n",
        "lisMulti = multiplicativeLFG(j, k, m, c, length)\n",
        "lisMultiNormalizada = np.array(normalize(lisMulti,m))  #normalización\n",
        "print(lisMulti)\n",
        "print(lisMultiNormalizada)\n",
        "\n",
        "lisSum = additiveLFG(j, k, m, length)\n",
        "lisSumNormalizada = np.array(normalize(lisSum,m))  #normalización\n",
        "print(lisSum)\n",
        "print(lisSumNormalizada)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUHKeHF9J0LZ"
      },
      "source": [
        "# 2. Implementar los algoritmos de pruebas de uniformidad ( Kolmogorov-Smirnov, χ2), y de independencia (corridas, series y poker)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLTIdOwOJ3vj"
      },
      "source": [
        "# Kolmogorov-Smirnov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eG32gNrTJ7bu"
      },
      "outputs": [],
      "source": [
        "# n := Cantidad de números aleatorios\n",
        "# c := Cantidad de intervalos\n",
        "\n",
        "n =  1000\n",
        "c = ceil(sqrt(n))\n",
        "gl = n  # Grados de libertad\n",
        "\n",
        "\n",
        "def uniformePEA(n):\n",
        "    lis = []\n",
        "    c = ceil(sqrt(n))\n",
        "    lis.append(1/c)\n",
        "    for i in range(c - 1):\n",
        "        lis.append( round(lis[len(lis) - 1] + (1/c), 2) )\n",
        "    return lis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39T_ig8VJaDL",
        "outputId": "ee5894c2-ad44-42b5-cd75-f6d463635188"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n"
          ]
        }
      ],
      "source": [
        "lsU_PEA = uniformePEA(100)\n",
        "print(lsU_PEA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DTLOUolOJdPc"
      },
      "outputs": [],
      "source": [
        "# Calcula el DMcalc del test de Kolmogorov-Smirnov\n",
        "def dmCalc_kolmogorov_Smirnov(n, lisFO):\n",
        "    c = len(lisFO)\n",
        "    gl = n  # Grados de libertad\n",
        "\n",
        "    lisPEA = uniformePEA(n)\n",
        "\n",
        "    lisFOA = [ lisFO[0] ]\n",
        "    for i in range(1, c):\n",
        "        lisFOA.append( lisFOA[i - 1] + lisFO[i] )\n",
        "    \n",
        "    lisPOA = list ( map ( lambda x: x / n , lisFOA ))\n",
        "\n",
        "    v1 = lisPEA[0]\n",
        "    v2 = lisPOA[0]\n",
        "    d = abs( lisPEA[0] - lisPOA[0] )\n",
        "    for i in range(1, c):\n",
        "        if ( abs( lisPEA[i] - lisPOA[i] ) > d ):\n",
        "            d = round( abs( lisPEA[i] - lisPOA[i] ), 2)\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgAUPWByJ30p",
        "outputId": "c87f0626-c0e7-4423-e5d0-08743e11e6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.04"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "foEj = [11, 6, 16, 9, 7, 11, 10, 9, 15, 6]  # Frecuencias Observadas de ejemplo visto en clase\n",
        "dmCalc_kolmogorov_Smirnov(100, foEj)  # Arroja el mismo valor para DMcalc obtenido en el ejemplo visto en clase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "e79hmcZLKz9d"
      },
      "outputs": [],
      "source": [
        "# Genera un arreglo con observaciones para intervalos de diez enteros \n",
        "# en base a un arreglo de frecuencias observadas arrayFO\n",
        "def crearObservacioens(arrayFO):\n",
        "    ejObs = []\n",
        "    for i in range (len(arrayFO)):\n",
        "        for j in range(arrayFO[i]):\n",
        "            ejObs.append((10 * i) + random.randint(0,9))\n",
        "    return ejObs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDa796eSK_yq",
        "outputId": "44818ca4-c37c-4c77-e0c0-f51684dea235"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ejObs = crearObservacioens(foEj)\n",
        "len(ejObs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zADAj02OLAy_"
      },
      "outputs": [],
      "source": [
        "# for a 0.01, 0.05 or 0.10 significance level\n",
        "def critValKolmogorov(n, significanceLevel):\n",
        "    if (significanceLevel == 0.01):\n",
        "        if (n > 20):\n",
        "            return 1.63 / sqrt(n)\n",
        "\n",
        "        elif (n == 5):\n",
        "            return 0.669\n",
        "        elif (n == 8):\n",
        "            return 0.543\n",
        "        elif (n == 10):\n",
        "            return 0.490\n",
        "        elif (n == 12):\n",
        "            return 0.450\n",
        "        elif (n == 15):\n",
        "            return 0.404\n",
        "        elif (n == 20):\n",
        "            return 0.356\n",
        "    elif (significanceLevel == 0.05):\n",
        "        if (n > 20):\n",
        "            return 1.36 / sqrt(n)\n",
        "\n",
        "        elif (n == 5):\n",
        "            return 0.565\n",
        "        elif (n == 8):\n",
        "            return 0.457\n",
        "        elif (n == 10):\n",
        "            return 0.410\n",
        "        elif (n == 12):\n",
        "            return 0.375\n",
        "        elif (n == 15):\n",
        "            return 0.338\n",
        "        elif (n == 20):\n",
        "            return 0.294\n",
        "    elif (significanceLevel == 0.10):\n",
        "        if (n > 20):\n",
        "            return 1.22 / sqrt(n)\n",
        "\n",
        "        elif (n == 5):\n",
        "            return 0.510\n",
        "        elif (n == 8):\n",
        "            return 0.411\n",
        "        elif (n == 10):\n",
        "            return 0.368\n",
        "        elif (n == 12):\n",
        "            return 0.338\n",
        "        elif (n == 15):\n",
        "            return 0.304\n",
        "        elif (n == 20):\n",
        "            return 0.264\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "gVnc0SyJkO7-"
      },
      "outputs": [],
      "source": [
        "def classifyKS(data, maxVal):\n",
        "    n = len(data)\n",
        "    c = ceil(sqrt(n))\n",
        "    freqList = np.zeros(c, dtype = int)\n",
        "    for i in range(n):\n",
        "        for j in range (1, c):\n",
        "            interv = c - 1\n",
        "            if (data[i] < (j *(maxVal / c)) ):\n",
        "                freqList[j] += 1\n",
        "                break\n",
        "    return freqList"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUgTNE6XUSEP",
        "outputId": "74c17cce-9679-4984-93f8-c60cf92df11c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Funciona para los valores de n: {5, 8, 10, 12, 15, 20}, para n > 20 \n",
        "# y para una significancia de 0.01, 0.05 o 0.10 \n",
        "def kolmogorovTest(data, maxVal, significanceLevel):\n",
        "    n = len(data)\n",
        "    lisFo = classifyKS(data, maxVal)\n",
        "    dmCalc = dmCalc_kolmogorov_Smirnov(n, lisFo)\n",
        "    critVal = critValKolmogorov(n, significanceLevel)\n",
        "    if (dmCalc > critVal):\n",
        "        #print(\"Se rechaza la hipotesis nula\")\n",
        "        return False\n",
        "    else:\n",
        "        #print(\"No se rechaza la hipotesis nula\")\n",
        "        return True\n",
        "\n",
        "kolmogorovTest(data, max(data), 0.05) #Se prueba la funcion con una secuencia uniforme generada por la libreria numpy, dando como resultado que si pasa la prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Gzgfum_J98b"
      },
      "source": [
        "# χ2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nogUXAwRKA9Q",
        "outputId": "29011c63-a9c4-4300-b130-1c5155f1ed87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "False\n"
          ]
        }
      ],
      "source": [
        "#Funcion que recibe un array de datos y un nivel de confianza ej: 0.05\n",
        "def chi2(data,nivelConfianza):\n",
        "  n= len(data)\n",
        "  c = round(sqrt(n),0)\n",
        "  gradosLibertad = int(c)-1\n",
        "  valorChi = stats.chi2.ppf(1-nivelConfianza, gradosLibertad)\n",
        "  miValorChi = hallarChiData(data)\n",
        "  #Verifico que el valor que halle de chi sea menor que el esperado\n",
        "  if(miValorChi <= valorChi):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "#Cuento cuantos datos hay en un determinado intervalo\n",
        "def contar(data,init,final):\n",
        "    n=0\n",
        "    for i in range(len(data)):\n",
        "      if(data[i]>=init and data[i]<final):\n",
        "        n +=1\n",
        "    return n\n",
        "\n",
        "#Se crean los intervalos y se van sumando los resultados para hallar mi valor de chi\n",
        "def hallarChiData(data):\n",
        "  n=len(data) #Tamaño array\n",
        "  c = round(sqrt(n),0) #Numero de clases\n",
        "  gradosLibertad = int(c)-1\n",
        "  FE = n/c #Frecuencia esperada\n",
        "  normalizaArray = normalize(data,max(data)) #Normalizo los datos\n",
        "  tamañoIntervalo = 1/c #Es 1/c debido a que se normalizaron\n",
        "  sum =0\n",
        "  inicioIntervalo=0\n",
        "  finIntervalo = tamañoIntervalo\n",
        "  for i in range(int(c)):\n",
        "    \n",
        "    #FO es contar la cantidad de veces que sale un num de data en un intervalo\n",
        "    FO = contar(normalizaArray,inicioIntervalo,finIntervalo )\n",
        "    if(finIntervalo==1):\n",
        "      FO +=1\n",
        "    sum += pow(FE-FO,2)/FE #Sumatoria para hallar chi\n",
        "    \"\"\"\n",
        "    Prints de apoyo para ver los intervalos generados\n",
        "    print('inicio')\n",
        "    print(inicioIntervalo)\n",
        "    print('fin')\n",
        "    print(finIntervalo)\n",
        "    print('FO')\n",
        "    print(FO)\n",
        "    print('-----------')\"\"\"\n",
        "    inicioIntervalo += tamañoIntervalo\n",
        "    finIntervalo +=  tamañoIntervalo\n",
        "  #Retorna mi valor de chi\n",
        "  return sum\n",
        "\n",
        "\n",
        "print(chi2(data,0.05)) #Se prueba la funcion con una secuencia uniforme generada por la libreria numpy, dando como resultado que si pasa la prueba\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-89sKKwKKnK"
      },
      "source": [
        "# Corridas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkKXkt0rKMcP",
        "outputId": "00c9c570-c9d1-4263-f410-f7aee3db6e49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "def corrida(data,numConfianza):\n",
        "  data = normalize(data,max(data)) #Normalizo los datos\n",
        "  contCrecimientoData = contarCrecimiento(data)[0] #Cuento cuantas subidas habia (crecimiento)\n",
        "  contDrecrecimientoData = (len(data)- contarCrecimiento(data)[0])-1 #Cuento cuantas bajadas habia (decrecimiento)\n",
        "  contCorridas = contarCrecimiento(data)[1] #Cuanto el numero de corridas\n",
        "\n",
        "  u = media(contCrecimientoData,contDrecrecimientoData) #media\n",
        "  vari = varianza(contCrecimientoData,contDrecrecimientoData) #varianza\n",
        "\n",
        "  nivelCon = nivelConfianza(numConfianza)\n",
        "\n",
        "  #Creacion de intervalo de confianza\n",
        "  limiteInferiorIntervalo = ((nivelCon*-1)*vari)+u\n",
        "  limiteeSuperiorIntervalo = (nivelCon*vari)+u\n",
        "\n",
        "  #Si mi numero de corridas esta dentro de intervalo de confianza para la prueba de lo contrario no\n",
        "  if(contCorridas>=limiteInferiorIntervalo and contCorridas<= limiteeSuperiorIntervalo):\n",
        "    return True #pasa la prueba\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "#Halla media\n",
        "def media(n1,n2):\n",
        "  u = ((2*n1*n2)/(n1+n2))+1\n",
        "  return u\n",
        "\n",
        "#Hallar varianza\n",
        "def varianza(n1,n2):\n",
        "  varianza = sqrt(((2*n1*n2)*(2*n1*n2-n1-n2))/(((n1+n2)**2)*(n1+n2+1)))\n",
        "  return varianza\n",
        "\n",
        "#Funcion para contar crecimiento y el numero de corridas\n",
        "def contarCrecimiento(data):\n",
        "  acumC =0\n",
        "  numCorridas =0\n",
        "  datos =[]\n",
        "  for i in range(len(data)-1):\n",
        "    if(data[i+1]>data[i]):\n",
        "      acumC += 1\n",
        "    else:\n",
        "      numCorridas +=1 \n",
        "  datos.append(acumC)\n",
        "  datos.append(numCorridas)\n",
        "  return datos\n",
        "\n",
        "#Tabla para niveles de confianza\n",
        "def nivelConfianza(num):\n",
        "  if(num==0.05):\n",
        "    return 1.96\n",
        "  elif(num==0.06):\n",
        "    return 1.88\n",
        "  elif(num==0.07):\n",
        "    return 1.81\n",
        "  elif(num==0.08):\n",
        "    return 1.75\n",
        "  elif(num==0.09):\n",
        "    return 1.69\n",
        "  elif(num==0.1):\n",
        "    return 1.65\n",
        "  elif(num==0.2):\n",
        "    return 1.28\n",
        "  elif(0.3773):\n",
        "    return 1\n",
        "  elif(num==0.5):\n",
        "    return 0.6745\n",
        "  else:\n",
        "    return \"error\"\n",
        "\n",
        "corrida(data,0.05) #Se prueba la funcion con una secuencia uniforme generada por la libreria numpy, dando como resultado que si pasa la prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "992inC-pKOC0"
      },
      "source": [
        "# series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lRgqctj_KP0e"
      },
      "outputs": [],
      "source": [
        "# Asumiendo que num pertenece al rango [0,1], y que dicho rango\n",
        "# está dividido en L intervalos, devuelve el número de intervalo\n",
        "# siendo el intervalo [0,0.1) el intervalo 0, para L = 10.\n",
        "def getInterval(num, L):\n",
        "    interStarts = [round(i*(1/L), 4) for i in range(L)]\n",
        "    #print(interStarts)\n",
        "\n",
        "    interval = L - 1\n",
        "    for i in range(len(interStarts) - 1):\n",
        "        if (num < interStarts[i + 1]):\n",
        "            interval = i\n",
        "            break\n",
        "    return interval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qx7T940JCOq1",
        "outputId": "c16367f0-8b73-47ee-ac79-f77116176836"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "getInterval(0.18, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZRN39Q7dIMc",
        "outputId": "04fbd9f1-5afd-4fde-bca9-6b7f467c3813"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "# Retorna True si los datos\n",
        "# pasan la prueba de series, False en caso contrario.\n",
        "\n",
        "# Se asume que len(datos) es múltiplo de k.\n",
        "\n",
        "def testSeries(datos, maxVal, k, conf):\n",
        "    datos = normalize(datos, maxVal)\n",
        "    n = len(datos)\n",
        "    g = int(n / k)       # Cantidad de grupos (tuplas)\n",
        "    c = ceil(sqrt(g))   # Cantidad de clases\n",
        "    intervs = ceil( pow( g, 1/(2*k) ) )  # Cantidad de intervalos para cada dimensión\n",
        "    #print(\"intervs\", intervs)\n",
        "    #Frecuencias observadas\n",
        "    frecObs = np.zeros((intervs ** (k - 1),intervs), dtype=int)   \n",
        "    #print(\"frecObs\", frecObs) \n",
        "    # for dim in range (k):\n",
        "    #     for i in range(n):\n",
        "    #         frecObs[datos[i][dim]][datos[i][dim + 1]] += 1\n",
        "\n",
        "    for i in range (g):\n",
        "        #col = getInterval(datos[i * k + (k - 1)], intervs)\n",
        "        col = getInterval(datos[i * k + (k - 1)], intervs)\n",
        "        row = 0\n",
        "        for dim in range (k - 1):\n",
        "            #print(\"row\", row)\n",
        "            row += getInterval(datos[i * k + dim], intervs) + (intervs ** ((k - 1) - dim - 1 )) - 1 #(intervs ** (dim))\n",
        "        #print(\"row, col\",row, col)\n",
        "        frecObs[row][col] += 1\n",
        "    #print(frecObs)\n",
        "\n",
        "    #Prueba de Chi cuadrado\n",
        "\n",
        "    # Se calcula la frecuencia esperada por clase\n",
        "    fe = g / c\n",
        "\n",
        "    finalMatrix = np.zeros((intervs ** (k - 1),intervs), dtype=float)\n",
        "    for i in range (intervs ** (k - 1)):\n",
        "        for j in range (intervs):\n",
        "            finalMatrix[i][j] = ((fe - frecObs[i][j]) ** 2) / fe\n",
        "\n",
        "    # Valor calculado para la prueba de Chi cuadrado\n",
        "    calculated = np.sum(finalMatrix)\n",
        "\n",
        "    # grados de libertad\n",
        "    freedomD = c - 1\n",
        "\n",
        "    # Valor crítico\n",
        "    criticVal = stats.chi2.ppf(1-conf, freedomD)\n",
        "\n",
        "    #print(\"Valor calculado: \", calculated)\n",
        "    #print(\"Valor crítico: \", criticVal)\n",
        "    return calculated <= criticVal\n",
        "\n",
        "print(testSeries(data,max(data),2,0.05)) #Se prueba la funcion con una secuencia uniforme generada por la libreria numpy, dando como resultado que si pasa la prueba"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J41brSqUKRNq"
      },
      "source": [
        "# poker "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akRhpgtrKSfu",
        "outputId": "5fe83646-4249-4111-ab17-cbb26e2207d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Funcion que recibe los array de datos y un nivel de confianza\n",
        "def poker(data,nivelConfianza):\n",
        "  n = len(data)\n",
        "  data = normalize2(data,max(data)) #Normalizo los datos de forma que me genere tres deciamales \n",
        "  sacarParteDecimal = decimal(data) #Saco la parte deciamles de los numeros normalizados\n",
        "\n",
        "  contarArr = contarPoker(sacarParteDecimal) #Funcion para contar dos y tres decimales iguales\n",
        "\n",
        "  dosIgules = contarArr[0] #Contar cuantos tienen dos decimales iguales\n",
        "  tresIguales = contarArr[1] #Contar cuantos tienen tres decimales iguales\n",
        "  distintos = len(data)-(dosIgules+tresIguales) #Contar cuantos tienen los tres deciamles diferentes\n",
        "  \n",
        "  #Hallo mi valor chi, en este casi son tres valores\n",
        "  miValorChi = (((0.01*len(data)-tresIguales)**2)/(0.01*len(data)*len(data))) + (((0.24*len(data)-dosIgules)**2)/(0.24*len(data)*len(data))) + (((0.72*len(data)-distintos)**2)/(0.72*len(data)*len(data))) \n",
        "  valorChi = stats.chi2.ppf(1-nivelConfianza, 2)\n",
        "\n",
        "  if(miValorChi <= valorChi):\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "#Sacar parte decimal de los datos y volverlo un entero\n",
        "def decimal(data):\n",
        "  arr = []\n",
        "  for i in range(len(data)):\n",
        "    parte_decimal, parte_entera = math.modf(data[i])\n",
        "    arr.append(int(parte_decimal*10))\n",
        "  return arr\n",
        "\n",
        "#Funcion para contar dos y tres decimales iguales (Se hace mediante operaciones matematicas)\n",
        "def contarPoker(data):\n",
        "  tresIguales= 0\n",
        "  dosIguales = 0\n",
        "  arr = []\n",
        "  for i in range(len(data)):\n",
        "    if(data[i]>0 and data[i]<=10):\n",
        "      dosIguales +=1\n",
        "    elif(data[i]==0):\n",
        "      tresIguales +=1\n",
        "    elif(data[i]>10 and data[i]<=99): #si 11 22\n",
        "      if(math.trunc(data[i]/10)==((data[i]/10)-math.trunc(data[i]/10)*10)):\n",
        "        dosIguales +=1\n",
        "    else:\n",
        "      if(math.trunc(data[i]/100)==math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10)==math.trunc(((((data[i]/100)-math.trunc(data[i]/100))*10)-math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10))*10)):\n",
        "        tresIguales +=1\n",
        "      elif(math.trunc(data[i]/100) == math.trunc(((((data[i]/100)-math.trunc(data[i]/100))*10)-math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10))*10) or\n",
        "           math.trunc(data[i]/100) == math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10) or\n",
        "           math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10)==math.trunc(((((data[i]/100)-math.trunc(data[i]/100))*10)-math.trunc(((data[i]/100)-math.trunc(data[i]/100))*10))*10)):\n",
        "        dosIguales +=1\n",
        "  \n",
        "  arr.append(dosIguales)\n",
        "  arr.append(tresIguales)\n",
        "  return arr\n",
        "\n",
        "poker(data,0.05) #Se prueba la funcion con una secuencia uniforme generada por la libreria numpy, dando como resultado que si pasa la prueba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9XVGGViKWmg"
      },
      "source": [
        "# 3. Usar las secuencias generadas en el primer punto para verificar su si pasan las pruebas del punto 2. (Usar como nivel de confianza por defecto 0.05)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMqlxd-yKbuq",
        "outputId": "e093a7d6-8404-4cd6-b3e7-534d0a262ef7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8234/2056996843.py:72: RuntimeWarning: overflow encountered in long_scalars\n",
            "  lst = np.append(lst, int( lst[len(lst) - j] * lst[len(lst) - k] + c ) % m )\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------Prueba a Von Neuman----------------------\n",
            "serie generada:\n",
            "[3168, 362, 1310, 7161, 2799, 8344, 6223, 7257, 6640, 896, 8028, 4487, 1331, 7715, 5212, 1649, 7192, 7248, 5335, 4622, 3628, 1623, 6341, 2082, 3347, 2024, 965, 9312, 7133, 8796, 3696, 6604, 6128, 5523, 5035, 3512, 3341, 1622, 6308, 7908, 5364, 7724, 6601, 5732, 8558, 2393, 7264, 7656, 6143, 7364, 2284, 2166, 6915, 8172, 7815, 742, 5505, 3050, 3025, 1506, 2680, 1824, 3269, 6863, 1007, 140, 196, 384, 1474, 1726, 9790, 8441, 2504, 2700, 2900, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100, 8100, 6100, 2100, 4100]\n",
            "-----Kolmogorov--------\n",
            "False\n",
            "-----Chi 2-------------\n",
            "False\n",
            "-----Corrida-----------\n",
            "True\n",
            "-----Serie-------------\n",
            "False\n",
            "-----Poker-------------\n",
            "True\n",
            "----------------------------Prueba a Congruencia----------------------\n",
            "serie generada:\n",
            "[100, 20002, 4000402, 800080402, 5397257746, 14299659794, 8073674258, 17007017490, 16969268754, 9419521554, 11298569746, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098, 9151086098]\n",
            "-----Kolmogorov--------\n",
            "False\n",
            "-----Chi 2-------------\n",
            "False\n",
            "-----Corrida-----------\n",
            "False\n",
            "-----Serie-------------\n",
            "False\n",
            "-----Poker-------------\n",
            "True\n",
            "----------------------------Fibunacci suma----------------------\n",
            "serie generada:\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.01, 0.02, 0.03, 0.04, 0.07, 0.11, 0.17, 0.28, 0.45, 0.73, 0.19, 0.92, 0.1, 0.02, 0.12, 0.15, 0.27, 0.42, 0.69, 0.11, 0.8, 0.9, 0.7, 0.6, 0.28, 0.45, 0.73, 0.19, 0.92, 0.1, 0.02, 0.13, 0.15, 0.27, 0.42, 0.69, 0.11, 0.8, 0.91, 0.7, 0.61, 0.29, 0.47, 0.76, 0.23, 0.98, 0.21, 0.19, 0.4, 0.6, 0.0, 0.6, 0.61, 0.21, 0.82, 0.03, 0.85, 0.88, 0.71, 0.16, 0.86, 0.02, 0.89, 0.91, 0.8, 0.68, 0.05, 0.74, 0.79, 0.53, 0.31, 0.84, 0.15, 1.0, 0.15, 0.13, 0.85, 0.97, 0.82, 0.79, 0.61, 0.4, 0.97, 0.52, 0.49, 0.02, 0.51, 0.52, 0.03, 0.56, 0.59, 0.15, 0.73, 0.45, 0.18, 0.64, 0.82, 0.46, 0.28, 0.68, 0.68, 0.36, 0.04, 0.4, 0.43, 0.83, 0.24, 0.65, 0.89, 0.52, 0.98, 0.5, 0.48, 0.98, 0.46, 0.43, 0.81, 0.53, 0.33, 0.86, 0.19, 0.05, 0.23, 0.22, 0.17, 0.39, 0.53, 0.49, 0.02, 0.51, 0.54, 0.05, 0.59, 0.54, 0.98, 0.52, 0.5, 0.01, 0.51, 0.52, 0.9, 0.85, 0.75, 0.57, 0.89, 0.46, 0.34, 0.78, 0.7, 0.48, 0.05, 0.96, 0.01, 0.97, 0.99, 0.96, 0.95, 0.71, 0.37, 0.08, 0.43, 0.08, 0.5, 0.58, 1.0, 0.86, 0.86, 0.59, 0.45, 0.04, 0.49, 0.52, 0.01, 0.54, 0.24, 0.35, 0.59, 0.92, 0.09, 0.01, 0.09, 0.9, 0.71, 0.61, 0.16, 0.34, 0.49, 0.83, 0.31, 0.71, 0.01, 0.3, 0.31, 0.61, 0.9, 0.07, 0.97, 0.04, 0.61, 0.08, 0.69, 0.58, 0.41, 1.0, 0.41, 0.31, 0.57, 0.88, 0.88, 0.76, 0.64, 0.38, 0.6, 0.98, 0.58, 0.85, 0.43, 0.28, 0.51, 0.5, 0.01, 0.5, 0.2, 0.28, 0.49, 0.04, 0.1, 0.14, 0.22, 0.9, 0.69, 0.59, 0.14, 0.74, 0.88, 0.4, 0.57, 0.97, 0.55, 0.81, 0.36, 0.17, 0.62, 0.51, 0.13, 0.62, 0.21, 0.26, 0.47, 0.03, 0.5, 0.53, 0.79, 0.17, 0.96, 0.13, 0.66, 0.79, 0.45, 0.13, 0.01, 0.14, 0.13, 0.41, 0.54, 0.96, 0.06, 0.6, 0.66, 0.0, 0.07, 0.64, 0.72, 0.8, 0.53, 0.34, 0.53, 0.58, 0.11, 0.68, 0.22, 0.91, 0.13, 0.69, 0.11, 0.8, 0.63, 0.28, 0.91, 0.19, 0.83, 0.03, 0.86, 0.31, 0.75, 0.07, 0.8, 0.89, 0.7, 0.58, 0.81, 0.12, 0.94, 0.75, 0.69, 0.45, 0.14, 0.89, 0.63, 0.53, 0.31, 0.83, 0.71, 0.52, 0.69, 0.23, 0.92, 0.34, 0.71, 0.05, 0.43, 0.92, 0.36, 0.27, 0.58, 0.75, 0.33, 0.94, 0.11, 0.62, 0.71, 0.52, 0.26, 0.78, 0.65, 0.46, 0.12, 0.23, 0.8, 0.05, 0.86, 0.39, 0.87, 0.26, 0.69, 0.8, 0.07, 0.85, 0.42, 0.9, 0.31, 0.97, 0.29, 0.83, 0.76, 0.49, 0.28, 0.78, 0.73, 0.58, 0.31, 0.13, 0.72, 0.43, 0.13, 1.0, 0.64, 0.64, 0.91, 0.4, 0.45, 0.47, 0.02, 0.54, 0.56, 0.39, 0.04, 0.43, 0.36, 0.53, 0.48, 0.99, 0.39, 0.51, 0.9, 0.6, 0.2, 0.52, 0.32, 0.43, 0.44, 0.87, 0.36, 0.33, 0.26, 0.12, 0.02, 0.76, 0.76, 0.12, 0.09, 0.21, 0.73, 0.93, 0.95, 0.45, 0.43, 0.08, 0.51, 0.26, 0.73, 0.71, 0.58, 0.03, 0.31, 0.32, 0.51, 0.13, 0.64, 0.09, 0.45, 0.43, 0.44, 0.82, 0.59, 0.41, 0.87, 0.93, 0.23, 0.9, 0.47, 0.75, 0.19, 0.87, 0.46, 0.89, 0.2, 0.47, 0.19, 0.2, 0.94, 0.68, 0.61, 0.59, 0.86, 0.18, 0.35, 0.89, 0.83, 0.7, 0.13, 0.19, 0.6, 0.79, 0.51, 0.5, 0.52, 0.45, 0.8, 0.25, 0.68, 0.31, 0.61, 0.79, 0.71, 0.42, 0.1, 1.0, 0.12, 0.84, 0.69, 0.97, 0.24, 0.71, 0.31, 0.26, 0.14, 0.88, 0.78, 0.8, 0.98, 0.64, 0.09, 0.72, 0.59, 0.98, 0.02, 0.04, 0.87, 0.07, 0.41, 0.44, 0.45, 0.75, 0.67, 0.29, 0.3, 0.5, 0.09, 0.9, 0.97, 0.27, 0.29, 0.63, 0.83, 0.57, 0.48, 0.51, 0.44, 0.57, 0.58, 0.36, 0.26, 0.54, 0.21, 0.4, 0.16, 0.11, 0.15, 0.08, 0.43, 0.81, 0.22, 0.58, 0.23, 0.02, 0.55, 0.6, 0.4, 0.13, 0.61, 0.61, 0.84, 0.61, 0.86, 0.82, 0.37, 0.73, 0.31, 0.31, 0.48, 0.2, 0.29, 0.85, 0.23, 0.23, 0.7, 0.1, 0.13, 0.28, 0.18, 0.44, 0.18, 0.63, 0.28, 0.52, 0.71, 0.64, 0.31, 0.44, 0.93, 0.67, 0.04, 0.92, 0.68, 0.35, 0.3, 0.73, 0.04, 0.58, 0.76, 0.89, 0.14, 0.55, 0.24, 0.17, 0.26, 0.3, 0.4, 0.36, 0.23, 0.15, 0.55, 0.59, 0.58, 0.27, 0.81, 0.47, 0.99, 0.26, 0.83, 0.42, 0.61, 0.44, 0.93, 0.68, 0.88, 0.94, 0.79, 0.86, 0.04, 0.5, 0.94, 0.85, 0.39, 0.66, 0.62, 0.13, 0.15, 0.65, 0.02, 0.69, 0.57, 0.02, 0.5, 0.03, 0.03, 0.3, 0.8, 0.34, 0.21, 0.62, 0.82, 0.17, 0.73, 0.72, 0.92, 0.83, 0.16, 0.56, 0.28, 0.33, 0.45, 0.63, 0.74, 0.73, 0.02, 0.09, 0.56, 0.6, 0.03, 0.76, 0.22, 0.86, 0.69, 0.55, 0.22, 0.9, 0.46, 0.59, 0.28, 0.76, 0.42, 0.58, 0.11, 0.06, 0.63, 0.06, 0.06, 0.02, 0.2, 0.9, 0.17, 0.03, 0.07, 0.18, 0.32, 0.2, 0.6, 0.58, 0.14, 0.39, 0.39, 0.08, 0.69, 0.8, 0.75, 0.21, 0.99, 0.74, 0.64, 0.1, 0.95, 0.54, 0.06, 0.28, 0.13, 0.36, 0.29, 0.84, 0.68, 0.97, 0.56, 0.17, 0.8, 0.1, 0.8, 0.27, 0.16, 0.01, 0.56, 0.25, 0.18, 0.3, 0.39, 0.36, 0.03, 0.99, 0.17, 0.16, 0.75, 0.94, 0.49, 0.18, 0.35, 0.85, 0.81, 0.31, 0.47, 0.17, 0.04, 0.03, 0.46, 0.98, 0.53, 0.23, 0.44, 0.88, 0.3, 0.78, 0.03, 0.03, 0.82, 0.37, 0.48, 0.26, 0.27, 0.84, 0.3, 0.61, 0.98, 0.1, 0.48, 0.62, 0.18, 0.69, 0.13, 0.06, 0.02, 0.99, 0.53, 0.23, 0.2, 0.76, 0.02, 0.66, 0.46, 0.79, 0.4, 0.95, 0.79, 0.22, 0.73, 0.59, 0.03, 0.55, 0.22, 0.97, 0.1, 0.5, 0.53, 0.05, 0.68, 0.28, 0.17, 0.88, 0.21, 0.06, 0.06, 0.03, 0.2, 0.02, 0.65, 0.7, 0.6, 0.29, 0.19, 0.66, 0.1, 0.7, 0.27, 0.7, 0.11, 0.41, 0.81, 0.08, 0.69, 0.66, 0.81, 0.05, 0.65, 0.39, 0.51, 0.92, 0.25, 0.14, 0.26, 0.48, 0.68, 0.21, 0.91, 0.34, 0.13, 0.37, 0.94, 0.98, 0.93, 0.86, 0.44, 0.57, 0.95, 0.45, 0.16, 0.91, 0.19, 0.27, 0.5, 0.1, 0.01, 0.23, 0.07, 0.2, 0.68, 0.04, 0.27, 0.26, 0.65, 0.63, 0.11, 0.97, 0.96, 0.84, 0.66, 0.01, 0.01, 0.26, 0.37, 0.33, 0.69, 0.36, 0.25, 0.18, 0.6, 0.77, 0.0, 0.05, 0.95, 0.9, 0.7, 0.1, 0.58, 0.96, 0.71, 0.53, 0.24, 0.87, 0.63, 0.75, 0.28, 0.61, 0.01, 0.07, 0.25, 0.64, 0.94, 0.97, 0.36, 0.23, 0.59, 0.82, 0.5, 0.2, 0.71, 0.29, 0.76, 0.29, 0.86, 0.38, 0.41, 0.93, 0.99, 0.19, 0.15, 0.96, 0.0, 0.59, 0.86, 0.45, 0.1, 0.41, 0.39, 0.34, 0.25, 0.57, 0.9, 0.64, 0.81, 0.63, 0.94, 0.43, 0.57, 0.01, 0.66, 0.11, 0.09, 0.03, 0.39, 0.75, 0.57, 0.83, 0.39, 0.41, 0.84, 0.52, 0.92, 0.71, 0.71, 0.43, 0.38, 0.07, 0.05, 0.09, 0.22, 0.54, 0.72, 0.57, 0.42, 0.26, 0.86, 0.94, 0.94, 0.31, 0.05, 0.96, 0.01, 0.29, 0.71, 0.85, 0.71, 0.17, 0.96, 0.29, 0.58, 0.09, 0.37, 0.95, 0.97, 0.32, 0.06, 0.62, 0.79, 0.4, 0.69, 0.56, 0.38, 0.63, 0.87, 0.68, 0.72, 0.96, 0.16, 0.41, 0.04, 0.2, 0.86, 0.78, 0.19, 0.22, 0.66, 0.55, 0.5, 0.31, 0.93]\n",
            "-----Kolmogorov--------\n",
            "True\n",
            "-----Chi 2-------------\n",
            "False\n",
            "-----Corrida-----------\n",
            "True\n",
            "-----Serie-------------\n",
            "False\n",
            "-----Poker-------------\n",
            "True\n",
            "----------------------------Fibunacci multiplicacion----------------------\n",
            "serie generada:\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.02, 0.05, 0.13, 0.33, 0.86, 0.25, 0.88, 0.39, 0.3, 0.5, 0.2, 0.09, 0.08, 0.16, 0.38, 1.0, 0.61, 0.83, 0.88, 0.81, 0.56, 0.87, 0.04, 0.24, 0.69, 0.84, 0.82, 0.63, 0.07, 0.57, 0.65, 0.77, 0.72, 0.44, 0.82, 0.29, 0.76, 0.94, 0.27, 0.55, 0.48, 0.45, 0.53, 0.53, 0.75, 0.0, 0.71, 0.76, 0.89, 0.58, 0.18, 0.47, 0.61, 0.39, 0.92, 0.89, 0.66, 0.78, 0.83, 0.63, 0.02, 0.92, 0.63, 0.6, 0.19, 0.48, 0.24, 0.25, 0.18, 0.67, 0.75, 0.94, 1.0, 0.55, 0.81, 0.93, 0.1, 0.71, 0.28, 0.68, 0.95, 0.01, 0.55, 0.58, 0.3, 0.98, 0.96, 0.62, 0.24, 0.88, 0.81, 0.97, 0.6, 0.39, 0.43, 0.28, 0.73, 0.64, 0.66, 0.09, 0.37, 0.3, 0.31, 0.7, 0.17, 0.16, 0.03, 0.64, 0.79, 0.97, 0.08, 0.81, 0.65, 0.69, 0.81, 0.51, 0.76, 0.68, 0.59, 0.63, 0.16, 0.54, 0.82, 0.22, 0.79, 0.76, 0.32, 0.48, 0.2, 0.95, 0.27, 0.32, 0.94, 0.94, 0.65, 0.18, 0.43, 0.66, 0.82, 0.47, 0.39, 0.17, 0.06, 0.13, 0.42, 0.87, 0.27, 0.89, 0.44, 0.02, 0.53, 0.31, 0.0, 0.98, 0.43, 0.3, 0.87, 0.59, 0.44, 0.96, 0.08, 0.71, 0.19, 0.5, 0.53, 0.13, 0.17, 0.87, 0.49, 0.46, 0.63, 0.42, 0.46, 0.87, 0.18, 0.54, 0.06, 0.42, 0.93, 0.54, 0.42, 0.11, 0.66, 0.05, 0.86, 0.59, 0.0, 0.48, 0.27, 0.29, 0.34, 0.1, 0.78, 0.68, 0.14, 0.58, 0.23, 0.04, 0.5, 0.45, 0.39, 0.48, 0.13, 0.81, 0.66, 0.04, 0.17, 0.97, 0.66, 0.47, 0.46, 0.3, 0.84, 0.62, 0.02, 0.57, 0.66, 0.37, 0.08, 0.85, 0.32, 0.46, 0.12, 0.27, 0.06, 0.9, 0.99, 0.29, 0.82, 0.79, 0.72, 0.78, 0.66, 0.13, 0.28, 0.98, 0.61, 0.61, 0.01, 0.94, 0.23, 0.26, 0.66, 0.7, 0.02, 0.68, 0.63, 0.93, 0.24, 0.67, 0.38, 0.98, 0.47, 1.0, 0.94, 0.64, 0.85, 0.56, 0.44, 0.03, 0.44, 0.07, 0.71, 0.06, 0.52, 0.73, 0.38, 0.56, 0.95, 0.51, 0.17, 0.6, 0.38, 0.11, 0.44, 0.98, 0.93, 0.01, 0.82, 0.03, 0.9, 0.37, 0.54, 0.26, 0.06, 0.55, 0.09, 0.13, 0.02, 0.78, 0.32, 0.71, 0.63, 0.09, 0.68, 0.86, 0.09, 0.1, 0.64, 0.63, 0.69, 0.11, 0.76, 0.62, 0.52, 0.71, 0.68, 0.12, 0.51, 0.6, 0.54, 0.56, 0.05, 0.42, 0.74, 0.13, 0.12, 0.25, 0.71, 0.11, 0.05, 0.93, 0.24, 0.06, 0.9, 0.84, 0.78, 0.46, 0.54, 0.46, 0.08, 0.67, 0.83, 0.13, 0.77, 0.62, 0.64, 0.68, 0.5, 0.44, 0.44, 0.52, 0.72, 0.43, 0.33, 0.26, 0.28, 0.36, 0.73, 0.57, 0.95, 0.67, 0.11, 0.93, 0.82, 0.69, 0.72, 0.79, 0.67, 0.5, 0.29, 0.15, 0.73, 0.06, 0.58, 0.48, 0.65, 1.0, 0.24, 0.85, 0.77, 0.08, 0.37, 0.14, 0.96, 0.18, 0.95, 0.84, 0.55, 0.28, 0.16, 0.3, 0.54, 0.43, 0.56, 0.87, 0.88, 1.0, 0.82, 0.31, 0.77, 0.04, 0.84, 0.44, 0.75, 0.21, 0.07, 0.98, 0.53, 0.36, 0.37, 0.87, 0.4, 0.39, 0.69, 0.4, 0.85, 0.02, 0.12, 0.81, 0.77, 0.6, 0.0, 0.45, 0.66, 0.5, 0.88, 0.47, 0.6, 0.64, 0.45, 0.24, 0.8, 0.37, 0.17, 0.55, 0.1, 0.05, 0.99, 0.06, 0.37, 0.8, 0.02, 0.74, 0.19, 0.77, 0.43, 0.85, 0.93, 0.52, 0.99, 0.85, 0.39, 0.77, 0.62, 0.69, 0.83, 0.9, 0.95, 0.3, 0.58, 0.05, 0.36, 0.11, 0.42, 0.68, 0.61, 0.21, 0.15, 0.13, 0.71, 0.55, 0.79, 0.68, 0.7, 0.05, 0.75, 0.75, 0.1, 0.79, 0.58, 0.41, 0.55, 0.71, 0.9, 0.66, 0.71, 0.58, 0.01, 0.59, 0.04, 0.37, 0.34, 0.29, 0.42, 0.76, 0.18, 0.41, 0.53, 0.02, 0.49, 0.35, 0.35, 0.27, 0.08, 0.43, 0.08, 0.7, 0.38, 0.55, 0.19, 0.56, 0.12, 0.52, 0.04, 0.98, 0.96, 0.92, 0.59, 0.11, 0.34, 0.62, 0.1, 0.2, 0.18, 0.47, 0.41, 0.82, 0.76, 0.21, 0.76, 0.34, 0.71, 0.32, 0.51, 0.36, 0.2, 0.63, 0.1, 0.08, 0.71, 0.74, 0.28, 0.47, 0.33, 0.2, 0.14, 0.57, 0.19, 0.77, 0.13, 0.16, 0.62, 0.37, 0.56, 0.75, 0.84, 0.12, 0.22, 0.57, 0.57, 0.73, 0.36, 0.48, 0.39, 0.38, 0.56, 0.01, 0.84, 0.24, 0.03, 0.31, 0.77, 0.96, 0.55, 0.03, 0.39, 0.64, 0.43, 0.52, 0.81, 0.05, 0.79, 0.97, 0.45, 0.2, 0.42, 0.52, 0.23, 0.36, 0.62, 0.91, 0.28, 0.92, 0.27, 0.87, 0.38, 0.19, 0.44, 0.78, 0.08, 0.96, 0.74, 0.27, 0.17, 0.79, 0.15, 0.31, 0.63, 0.2, 0.18, 0.46, 0.18, 0.83, 0.76, 0.39, 0.11, 0.8, 0.74, 0.79, 0.36, 0.27, 0.4, 0.4, 0.18, 0.25, 0.98, 0.52, 0.27, 0.91, 0.17, 0.57, 0.12, 0.58, 0.99, 0.0, 0.98, 0.85, 0.54, 0.7, 0.8, 0.48, 0.16, 0.35, 0.42, 0.25, 0.22, 0.07, 0.97, 0.7, 0.79, 0.51, 0.11, 0.23, 0.06, 0.97, 0.3, 0.98, 0.02, 0.5, 0.84, 0.09, 0.28, 0.51, 0.99, 0.14, 0.07, 0.59, 0.22, 0.7, 0.91, 0.18, 0.43, 0.91, 0.96, 0.38, 0.28, 0.4, 0.09, 0.51, 0.46, 0.29, 0.9, 0.79, 0.54, 0.15, 0.62, 0.71, 0.99, 0.71, 0.82, 0.97, 0.73, 0.89, 0.92, 0.56, 0.91, 0.4, 0.4, 0.27, 1.0, 0.88, 0.32, 0.44, 0.04, 0.95, 0.72, 0.69, 0.56, 0.08, 0.23, 0.97, 0.96, 0.01, 0.02, 0.79, 0.72, 0.3, 0.71, 0.01, 0.34, 0.9, 0.92, 0.26, 0.71, 0.95, 0.89, 0.52, 0.77, 0.54, 0.19, 0.83, 0.4, 0.6, 0.67, 0.4, 0.41, 0.21, 0.39, 0.69, 0.27, 0.27, 0.53, 0.1, 0.02, 0.25, 0.47, 0.85, 0.15, 0.9, 0.44, 0.96, 0.16, 0.81, 0.62, 0.76, 0.47, 0.25, 0.93, 0.11, 0.45, 0.87, 0.37, 0.5, 0.38, 0.46, 0.84, 0.86, 0.55, 0.21, 0.07, 0.53, 0.94, 0.22, 0.54, 0.95, 0.63, 0.07, 0.7, 0.69, 0.09, 0.22, 0.42, 0.34, 0.71, 0.54, 0.55, 0.68, 0.77, 0.71, 0.32, 0.78, 0.74, 0.89, 0.29, 0.58, 0.96, 0.08, 0.03, 0.62, 0.34, 0.85, 0.38, 0.78, 0.15, 1.0, 0.1, 0.03, 0.84, 0.35, 0.49, 0.73, 0.66, 0.64, 0.28, 0.77, 0.49, 0.9, 0.74, 0.95, 0.96, 0.36, 0.46, 0.59, 0.17, 0.21, 0.99, 0.75, 0.47, 0.27, 0.22, 0.57, 0.29, 0.12, 0.12, 0.25, 0.56, 0.91, 0.67, 0.95, 0.28, 0.71, 0.47, 0.63, 0.45, 0.28, 0.94, 0.13, 0.92, 0.61, 0.27, 0.65, 0.07, 0.75, 0.76, 0.28, 0.46, 0.07, 0.49, 0.07, 0.52, 0.25, 0.76, 0.27, 0.85, 0.97, 0.27, 0.39, 0.94, 0.6, 0.56, 0.01, 0.58, 0.05, 0.02, 0.63, 0.71, 0.67, 0.34, 0.08, 0.27, 0.11, 0.33, 0.82, 0.59, 0.38, 0.42, 0.76, 0.37, 0.41, 0.71, 0.81, 0.7, 0.01, 0.69, 0.52, 0.46, 0.68, 0.21, 0.07, 0.85, 0.76, 0.89, 0.96, 0.05, 0.33, 0.05, 0.88, 0.95, 0.13, 0.83, 0.18, 0.22, 0.44, 0.61, 0.33, 0.7, 0.97, 0.92, 0.47, 0.68, 0.67, 0.58, 0.09, 0.1, 0.96, 0.32, 0.09, 0.28, 0.09, 0.62, 0.39, 0.96, 0.28, 0.15, 0.72, 0.17, 0.16, 0.09, 0.39, 0.62, 0.61, 0.28, 0.75, 0.03, 0.26, 0.63, 0.04, 0.5, 0.08, 0.18, 0.63, 0.04, 0.19, 0.1, 0.36, 0.53, 0.43, 0.39, 0.73, 0.19, 0.38, 0.46, 0.33, 0.87, 0.52, 0.01, 0.5, 0.09, 0.49, 0.16, 0.65, 0.55, 0.61, 0.11, 0.27, 0.69, 0.77, 0.69, 0.81, 0.56, 0.72, 0.87, 0.59, 0.68, 0.42, 0.28, 0.23, 0.75, 0.86, 0.76, 0.89, 0.69, 0.86, 0.3, 0.34, 0.52, 0.05, 0.38, 0.7]\n",
            "-----Kolmogorov--------\n",
            "True\n",
            "-----Chi 2-------------\n",
            "False\n",
            "-----Corrida-----------\n",
            "True\n",
            "-----Serie-------------\n",
            "True\n",
            "-----Poker-------------\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "length = 1000\n",
        "m = 2**34 \n",
        "\n",
        "#Congruencia\n",
        "n = 100\n",
        "a = 200\n",
        "c = 1283 \n",
        "\n",
        "#Von Neuman\n",
        "nVonNeuman = 3168 \n",
        "\n",
        "#Fibu\n",
        "j = 17\n",
        "k = 41\n",
        "c = 2\n",
        "\n",
        "#Funciones generadas en el punto 1\n",
        "pruebaVonNeuman =  vonNeumanList(nVonNeuman, length)\n",
        "pruebaCongruencia = congruenciaList(n, length, a, c, m)\n",
        "pruebaFibunacciSuma = additiveLFG(j, k, m, length)\n",
        "pruebaFibunacciMulti = multiplicativeLFG(j, k, m, c, length)\n",
        "\n",
        "#Funciones generadas en el punto 2\n",
        "print('----------------------------Prueba a Von Neuman----------------------')  #True paso la prueba, False sino\n",
        "print('serie generada:')\n",
        "print(pruebaVonNeuman) #Lista de 1000 datos generados por Von Neuman\n",
        "print(\"-----Kolmogorov--------\")\n",
        "print(kolmogorovTest(pruebaVonNeuman, max(pruebaVonNeuman), 0.05)) #datos, num maximo, nivel de confianza \n",
        "print(\"-----Chi 2-------------\")\n",
        "print(chi2(pruebaVonNeuman,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Corrida-----------\")\n",
        "print(corrida(pruebaVonNeuman,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Serie-------------\")\n",
        "print(testSeries(pruebaVonNeuman, max(pruebaVonNeuman), 2, 0.05)) #datos, num maximo de los datos, pares y confianza\n",
        "print(\"-----Poker-------------\")\n",
        "print(poker(pruebaVonNeuman,0.05))#datos y nivel de confianza\n",
        "\n",
        "print('----------------------------Prueba a Congruencia----------------------') #True paso la prueba, False sino\n",
        "print('serie generada:')\n",
        "print(pruebaCongruencia) #Lista de 1000 datos generados por congruencia\n",
        "print(\"-----Kolmogorov--------\")\n",
        "print(kolmogorovTest(pruebaCongruencia, max(pruebaCongruencia), 0.05)) #datos, num maximo, nivel de confianza \n",
        "print(\"-----Chi 2-------------\") \n",
        "print(chi2(pruebaCongruencia,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Corrida-----------\")\n",
        "print(corrida(pruebaCongruencia,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Serie-------------\")\n",
        "print(testSeries(pruebaCongruencia, max(pruebaCongruencia), 2, 0.05)) #datos, num maximo de los datos, pares y confianza\n",
        "print(\"-----Poker-------------\")\n",
        "print(poker(pruebaCongruencia,0.05))#datos y nivel de confianza\n",
        "\n",
        "print('----------------------------Fibunacci suma----------------------') #True paso la prueba, False sino\n",
        "print('serie generada:')\n",
        "print(normalize(pruebaFibunacciSuma,m)) #Para una mejor visualizacion de los datos 100 datos se normalizo\n",
        "print(\"-----Kolmogorov--------\")\n",
        "print(kolmogorovTest(pruebaFibunacciSuma, max(pruebaFibunacciSuma), 0.05)) #datos, num maximo, nivel de confianza \n",
        "print(\"-----Chi 2-------------\") \n",
        "print(chi2(pruebaFibunacciSuma,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Corrida-----------\") \n",
        "print(corrida(pruebaFibunacciSuma,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Serie-------------\")\n",
        "print(testSeries(pruebaFibunacciSuma, max(pruebaFibunacciSuma), 2, 0.05)) #datos, num maximo de los datos, pares y confianza\n",
        "print(\"-----Poker-------------\")\n",
        "print(poker(pruebaFibunacciSuma,0.05))#datos y nivel de confianza\n",
        "\n",
        "print('----------------------------Fibunacci multiplicacion----------------------')  #True paso la prueba, False sino\n",
        "print('serie generada:')\n",
        "print(normalize(pruebaFibunacciMulti,m))#Para una mejor visualizacion de los datos 100 datos se normalizo\n",
        "print(\"-----Kolmogorov--------\")\n",
        "print(kolmogorovTest(pruebaFibunacciMulti, m - 1, 0.05)) #datos, num maximo, nivel de confianza\n",
        "print(\"-----Chi 2-------------\") \n",
        "print(chi2(pruebaFibunacciMulti,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Corrida-----------\") \n",
        "print(corrida(pruebaFibunacciMulti,0.05)) #datos y nivel de confianza\n",
        "print(\"-----Serie-------------\")\n",
        "print(testSeries(pruebaFibunacciMulti, max(pruebaFibunacciMulti), 2, 0.05)) #datos, num maximo de los datos, pares y confianza\n",
        "print(\"-----Poker-------------\")\n",
        "print(poker(pruebaFibunacciMulti,0.05))#datos y nivel de confianza"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wei7TUX4Klcz"
      },
      "source": [
        "# 4. Graficar las distribuciones de probabilidad de las frecuencias observadas, analizar los resultados obtenidos en las pruebas del punto 3 y escribir conclusiones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "ixitGwHi0Dp-",
        "outputId": "cd759f8b-6858-42c2-8af5-1f38a44e0f5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------Von neuman------------------\n",
            "Frequency of unique values of the said array:\n",
            "[[ 140  196  362  384  742  896  965 1007 1310 1331 1474 1506 1622 1623\n",
            "  1649 1726 1824 2024 2082 2100 2166 2284 2393 2504 2680 2700 2799 2900\n",
            "  3025 3050 3168 3269 3341 3347 3512 3628 3696 4100 4487 4622 5035 5212\n",
            "  5335 5364 5505 5523 5732 6100 6128 6143 6223 6308 6341 6601 6604 6640\n",
            "  6863 6915 7133 7161 7192 7248 7257 7264 7364 7656 7715 7724 7815 7908\n",
            "  8028 8100 8172 8344 8441 8558 8796 9312 9790]\n",
            " [   1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "     1    1    1    1    1  231    1    1    1    1    1    1    1    1\n",
            "     1    1    1    1    1    1    1    1    1  232    1    1    1    1\n",
            "     1    1    1    1    1  231    1    1    1    1    1    1    1    1\n",
            "     1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
            "     1  231    1    1    1    1    1    1    1]]\n",
            "Probabilidades:  [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.231 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.232 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.231\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.231\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nConclusiones:\\n*Se ejecuto varias veces el generador de numeros aleatorias y en varias ocaciones no paso la prueba de uniformidad, pero no se debe a que sea un mal generador\\nsino que algunas veces tiene algunos picos lo cual hace que no pase la prueba\\n*Paso las pruebas de independencia lo cual significa que no existian patrones dentro de los numeros\\n*En general podemos decir que es un buen generador y facil de implementar, sin embargo puede demorar algo su ejecucion y la semilla en este caso debe ser un numero de 4 digitos\\n\\n'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"----------------Von neuman------------------\")\n",
        "listaVonNeuman = np.array( pruebaVonNeuman )\n",
        "\n",
        "unique_elements_von, counts_elements_von = np.unique(listaVonNeuman, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements_von, counts_elements_von)))\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsVon = counts_elements_von / length;\n",
        "print(\"Probabilidades: \", probsVon)\n",
        "\n",
        "plt.plot(probsVon)\n",
        "\n",
        "\"\"\"\n",
        "Conclusiones:\n",
        "*Se ejecuto varias veces el generador de numeros aleatorias y en varias ocaciones no paso la prueba de uniformidad, pero no se debe a que sea un mal generador\n",
        "sino que algunas veces tiene algunos picos lo cual hace que no pase la prueba\n",
        "*Paso las pruebas de independencia lo cual significa que no existian patrones dentro de los numeros\n",
        "*En general podemos decir que es un buen generador y facil de implementar, sin embargo puede demorar algo su ejecucion y la semilla en este caso debe ser un numero de 4 digitos\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "0pHTNc0i0Zdx",
        "outputId": "7cbc1e04-c7e6-4657-dedd-29f23b2ad64a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------Congruencia------------------\n",
            "Frequency of unique values of the said array:\n",
            "[[        100       20002     4000402   800080402  5397257746  8073674258\n",
            "   9151086098  9419521554 11298569746 14299659794 16969268754 17007017490]\n",
            " [          1           1           1           1           1           1\n",
            "          989           1           1           1           1           1]]\n",
            "Probabilidades:  [0.001 0.001 0.001 0.001 0.001 0.001 0.989 0.001 0.001 0.001 0.001 0.001]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nConclusiones:\\n*Se ejecuto varias veces el generador de numeros aleatorias y en varias ocaciones igual que el anterior no paso la prueba de uniformidad, esto se debe que casi siempre se poduce un pico en el algoritmo\\n, este pico se puede deber a muchas cosas que explicare a continuaciones, en nuestra opinion este algoritmo tiene una desventaja y es que para generar los numeros depende de muchas entradas y al minimo\\ncambio que se le haga a una puede generar una salida muy distinta, entonces es muy importante saber cuales seran las entradas y hay algunos consejos de como escogerlos, sin embargo puede que estas \\nrecomendaciones no siempre nos sirvan.\\n*En el caso de las pruebas de independencia la que casi siempre pasaba era la de poker, una de las posibles razones de que no pasara las otras es que siempre se hace modulo\\na un mismo numero por lo que se pueden empezar a encontrar patrones\\n*En general la congruencia puede ser un buen generador porque es rapido pasa algunas pruebas de independencia y uniformanidad, sin embargo tiene la desventaja de que cualquier \\nmodificacion en uno de sus parametros puede afectar significativamente al resultado\\n\\n'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"----------------Congruencia------------------\")\n",
        "listaCongruencia = np.array( pruebaCongruencia  )\n",
        "\n",
        "unique_elements_con, counts_elements_con = np.unique(listaCongruencia, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements_con, counts_elements_con)))\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsCon = counts_elements_con / length;\n",
        "print(\"Probabilidades: \", probsCon)\n",
        "\n",
        "plt.plot(probsCon)\n",
        "\n",
        "\"\"\"\n",
        "Conclusiones:\n",
        "*Se ejecuto varias veces el generador de numeros aleatorias y en varias ocaciones igual que el anterior no paso la prueba de uniformidad, esto se debe que casi siempre se poduce un pico en el algoritmo\n",
        ", este pico se puede deber a muchas cosas que explicare a continuaciones, en nuestra opinion este algoritmo tiene una desventaja y es que para generar los numeros depende de muchas entradas y al minimo\n",
        "cambio que se le haga a una puede generar una salida muy distinta, entonces es muy importante saber cuales seran las entradas y hay algunos consejos de como escogerlos, sin embargo puede que estas \n",
        "recomendaciones no siempre nos sirvan.\n",
        "*En el caso de las pruebas de independencia la que casi siempre pasaba era la de poker, una de las posibles razones de que no pasara las otras es que siempre se hace modulo\n",
        "a un mismo numero por lo que se pueden empezar a encontrar patrones\n",
        "*En general la congruencia puede ser un buen generador porque es rapido pasa algunas pruebas de independencia y uniformanidad, sin embargo tiene la desventaja de que cualquier \n",
        "modificacion en uno de sus parametros puede afectar significativamente al resultado\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bT7Mf22wKooJ",
        "outputId": "eed14edd-b6cf-4859-e72e-368a6355baff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------Fibu suma------------------\n",
            "Frequency of unique values of the said array:\n",
            "[[      46368       75026      121394 ... 17111809166 17122630984\n",
            "  17177297678]\n",
            " [          1           1           1 ...           1           1\n",
            "            1]]\n",
            "Probabilidades:  [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nConclusiones:\\n*En comparacion con los otros generadores este fue el mejor, lo podemos evidenciar en que pasa la mayoria de pruebas de uniformidad y diversidad, ademas lo podemos ver por medio \\nde la grafica, nos muestra uniformidad\\n*El generador de fibonacci aditivo es útil para generar series pseudoaleatoriasbuenas, y con los parámetros adecuados su periodo es largo.\\n\\n'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"----------------Fibu suma------------------\")\n",
        "listaFibuSum = np.array( pruebaFibunacciSuma )\n",
        "\n",
        "unique_elements_fibu_sum, counts_elements_fibu_sum = np.unique(listaFibuSum, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements_fibu_sum, counts_elements_fibu_sum)))\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsFibuSum = counts_elements_fibu_sum / length;\n",
        "print(\"Probabilidades: \", probsFibuSum)\n",
        "\n",
        "plt.plot(probsFibuSum)\n",
        "\"\"\"\n",
        "Conclusiones:\n",
        "*En comparacion con los otros generadores este fue el mejor, lo podemos evidenciar en que pasa la mayoria de pruebas de uniformidad y diversidad, ademas lo podemos ver por medio \n",
        "de la grafica, nos muestra uniformidad\n",
        "*El generador de fibonacci aditivo es útil para generar series pseudoaleatoriasbuenas, y con los parámetros adecuados su periodo es largo.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1aUhsfJT0WnE",
        "outputId": "b9bf9d9a-1613-4d2d-b16a-e1f7e9a20df4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------Fibu multiplicacion------------------\n",
            "Frequency of unique values of the said array:\n",
            "[[          2       75027      121395 ... 17153401254 17160203174\n",
            "  17176829862]\n",
            " [          1           1           1 ...           1           1\n",
            "            1]]\n",
            "Probabilidades:  [0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.002 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001 0.001\n",
            " 0.001 0.001 0.001]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nConclusiones:\\n*Este tambien fue uno de los mejores generadores, paso la mayoria de pruebas de uniformidad y diversidad\\nEl generador de fibonacci multiplicativo es bueno para generar series de números\\npseudoaleatorios. Con los parámetros adecuados es muy bueno a la hora de no \\ncaer en patrones predecibles, pero corre el riesgo de converger a cero, por lo que \\nse adicionó un parámetro adicional al cálculo que permite evitar dicha convergencia.\\n\\n'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"----------------Fibu multiplicacion------------------\")\n",
        "listaFibuMul = np.array( pruebaFibunacciMulti )\n",
        "\n",
        "unique_elements_fibu_mul, counts_elements_fibu_mul = np.unique(listaFibuMul, return_counts=True)\n",
        "print(\"Frequency of unique values of the said array:\")\n",
        "print(np.asarray((unique_elements_fibu_mul, counts_elements_fibu_mul)))\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsFibuMul = counts_elements_fibu_mul / length;\n",
        "print(\"Probabilidades: \", probsFibuMul)\n",
        "\n",
        "plt.plot(probsFibuMul)\n",
        "\"\"\"\n",
        "Conclusiones:\n",
        "*Este tambien fue uno de los mejores generadores, paso la mayoria de pruebas de uniformidad y diversidad\n",
        "El generador de fibonacci multiplicativo es bueno para generar series de números\n",
        "pseudoaleatorios. Con los parámetros adecuados es muy bueno a la hora de no \n",
        "caer en patrones predecibles, pero corre el riesgo de converger a cero, por lo que \n",
        "se adicionó un parámetro adicional al cálculo que permite evitar dicha convergencia.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlq9BiDCK6EE"
      },
      "source": [
        "# PDF practica1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "A_WXlSueK9W6",
        "outputId": "dd94aa73-179c-440d-e331-0a048fa33b71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probabilidades:  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02]\n",
            "Chi con confianza de 0.01\n",
            "True\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Aplique la prueba de Chi-Cuadrado con una confianza de 0.01 a los siguientes datos:\n",
        "\n",
        "datosPractica1 = [0.424 ,0.879, 0.927 ,0.993, 0.340 ,0.633 ,0.363, 0.700 ,0.828 ,0.787 ,0.117 ,0.147 ,0.093, 0.502,\n",
        "0.247, 0.993 ,0.465 ,0.595 ,0.509, 0.344 ,0.565 ,0.294 ,0.933 ,0.950 ,0.944 ,0.936, 0.448 ,0.821\n",
        ",0.461 ,0.599 ,0.585 ,0.693 ,0.731 ,0.935 ,0.578 ,0.232 ,0.462 ,0.001, 0.309 ,0.319 ,0.577 ,0.531\n",
        ",0.642 ,0.534 ,0.707 ,0.120 ,0.740 ,0.648 ,0.238 ,0.002 ,0.010 ,0.688 ,0.286 ,0.512 ,0.655 ,0.452\n",
        ",0.025 ,0.699 ,0.555 ,0.072 ,0.981 ,0.113 ,0.500 ,0.811 ,0.843 ,0.924, 0.144 ,0.057 ,0.008 ,0.250\n",
        ",0.053 ,0.531 ,0.596 ,0.299 ,0.726 ,0.569 ,0.677 ,0.726 ,0.785 ,0.844 ,0.164 ,0.714 ,0.044 ,0.077\n",
        ",0.602 ,0.262 ,0.053 ,0.023 ,0.482 ,0.418 ,0.505 ,0.052 ,0.850 ,0.680 ,0.550 ,0.287 ,0.378 ,0.177\n",
        ",0.820 ,0.528 ]\n",
        "\n",
        "listaP1 = np.array( datosPractica1 )\n",
        "\n",
        "unique_elements_P1, counts_elements_P1 = np.unique(listaP1 , return_counts=True)\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsP1 = counts_elements_P1 / len(datosPractica1);\n",
        "print(\"Probabilidades: \", probsP1 )\n",
        "\n",
        "plt.plot(probsP1 )\n",
        "\n",
        "#De esta secuencia de numeros podemos decir que es una secuencia uniforme, ya que pasa la prueba con una confianza de 0.01 es decir 99%. Tambien lo podemos apreciar en el grafico\n",
        "\n",
        "print(\"Chi con confianza de 0.01\")\n",
        "print(chi2(datosPractica1,0.01))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqIPmdW5LARi"
      },
      "source": [
        "# PDF practica2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "jzDNerITLC7a",
        "outputId": "ba7414a5-b8a1-4a9a-d053-09c8f8df297e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Probabilidades:  [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.02 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
            " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.02]\n",
            "-----corrida con confianza de 0.05-------\n",
            "True\n",
            "-----corrida con confianza de 0.1-------\n",
            "True\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Aplicar corridas\n",
        "\n",
        "datosPractica2 = [0.424,0.879,0.927,0.993,0.340,0.633,0.363,0.700,0.828,0.787,0.117,0.147,0.093,0.502\n",
        ",0.247,0.993,0.465,0.595,0.509,0.344,0.565,0.294,0.933,0.950,0.944,0.936,0.448,0.821\n",
        ",0.461,0.599,0.585,0.693,0.731,0.935,0.578,0.232,0.462,0.001,0.309,0.319,0.577,0.531\n",
        ",0.642,0.534,0.707,0.120,0.740,0.648,0.238,0.002,0.010,0.688,0.286,0.512,0.655,0.452\n",
        ",0.025,0.699,0.555,0.072,0.981,0.113,0.500,0.811,0.843,0.924,0.144,0.057,0.008,0.250\n",
        ",0.053,0.531,0.596,0.299,0.726,0.569,0.677,0.726,0.785,0.844,0.164,0.714,0.044,0.077\n",
        ",0.602,0.262,0.053,0.023,0.482,0.418,0.505,0.052,0.850,0.680,0.550,0.287,0.378,0.177\n",
        ",0.820,0.528]\n",
        "\n",
        "listaP2 = np.array( datosPractica2 )\n",
        "\n",
        "unique_elements_P2, counts_elements_P2 = np.unique(listaP2 , return_counts=True)\n",
        "\n",
        "## normalizado = unique_elements / m\n",
        "probsP2 = counts_elements_P2 / len(datosPractica1);\n",
        "print(\"Probabilidades: \", probsP2 )\n",
        "\n",
        "plt.plot(probsP2 )\n",
        "\n",
        "#De esta secuencia de numeros podemos decir que no hay patrones o secuencias entre los numeros, paso la prueba para valor de confianza de 0.05 y 0.1\n",
        "\n",
        "#confianza 0.05\n",
        "print(\"-----corrida con confianza de 0.05-------\")\n",
        "print(corrida(datosPractica2,0.05))\n",
        "\n",
        "#confianza 0.1\n",
        "print(\"-----corrida con confianza de 0.1-------\")\n",
        "print(corrida(datosPractica2,0.1))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "X85K0q_0JbS9",
        "lxK56imVJLxg",
        "NX-m6qD-JsQY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "66e37a4da3c390ba9102db785636e2db61d518923b2ca2e4091350072f76ee72"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
